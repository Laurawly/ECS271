\documentclass{article}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage{subfig}
\usepackage{epsfig}
\usepackage{epstopdf}
\usepackage{amsmath}
\linespread{1.2}



\title{ECS 271 Homework1}
\date{\vspace{-5ex}}
\begin{document}
\author{Jiahui Guan, Leyuan Wang}
\maketitle


\section{Problem 1} 
\subsection{K-nn}
We implemented k-nearest neighbor algorithm with three different k's: k=1,k=5,k=50. When testing a data, we calculate its distances of all the training data. Note that here we use Euclidean distance and in this case its a 16-dimensional Euclidean distance. Then we choose the nearest $k$ points. Nearest means the smallest $k$ Euclidean distance from the specific testing data. Note that when $k=1$, we just only pick up the nearest point. After getting those nearest neighbors, we count which class they fall into. Here is which digits they "come from". We pick up the one that appears the most. \\

The algorithm is pretty easy to implement without using any package. We use R to write the code. Detailed R code can be found at Appendix. One thing needed to be noticed is that when $k=1$, it will automatically result in overfitting. Similary, when k is very large, it will produce underfitting. Here for $k=50$, it's hard to say it will cause underfitting without looking into the real data.\\

\subsection{SVM}
We use Python to implement Support Vector Machine (SVM). To do that, we first need to find a hyperplan that separate two groups. That is: 
\[x_iw+b \geq +1, y_i=+1\]
\[x_iw+b \leq -1 , y_i=-1\]
Since we have digit 0-9, total 10 levels, we each time separate one digit. That is treat "0" to be +1 and the rest to be -1. To keept the consistency, we make all the digit to be +1 and the rest to be -1. 

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
& digit & the others\\
\hline
\hline 
0&+1&-1\\
1&+1&-1\\
2&+1&-1\\
3&+1&-1\\
4&+1&-1\\
5&+1&-1\\
6&+1&-1\\
7&+1&-1\\
8&+1&-1\\
9&+1&-1\\
\hline
\end{tabular}

\end{table}

Then for each digit vs the-others svm, we use lagrange multipliers to sovle the quadric programming (QP) problem. That is:
\begin{equation*}
\texttt{minimize:} W(\alpha) =-\sum_{i=1}^l \alpha_i +\dfrac{1}{2}\sum_{i=1}^ly_iy_j\alpha_i\alpha_j(x_ix_j)
\end{equation*}
\begin{equation*}
\texttt{subject:} \sum_{i=1}^ly_i\alpha_i=0, 0\leq\alpha_i\leq C (\forall i)
\end{equation*}

This QP problem can be solved using \textit{cvxopt.solvers} in Python. we can get the estimated $\alpha_i$. 
By taking the derivative with respect to $w$ and $b$, we can get $w=\sum_i \alpha_iy_ix_i$.\\

To determine b, we need to take any positive and negative support vector, $x+$ and $x-$. 
\[(wx^+ +b)=+1\]
\[(wx^- +b)=-1\]
By solving these equations, we can get $b=-\dfrac{1}{2}(wx^+ +wx^-)$.

\subsection{Kernel}
Since it is good to project to a higher dimension (higher than 16-dim in this case), we first apply three differents kernels: Linear, Gaussian and Polynomial. Note that when svm for each digit-vs-the-others, we use the same kernel for all the 0-9 digits. Note that when applying kernels, we change $x$ to be $\phi(x)$, where $\phi(x_a)\phi(x_b)=K(x_a,x_b)$ \\


\begin{itemize}
\item Linear Kernel: $K(x_a,x_b)=x_ax_b$ (inner product) \\
\item Gaussian Kernel: $K(x_a,x_b)=\exp (-\dfrac{||x_a-x_b||^2}{2 \sigma^2} )$ \\
  Our experiments show that the best $\sigma^2= \sqrt{8}$. \\
  That is make $1/(2\sigma^2)=1/dim(x)=1/16$
  
\item Polynomial Kernel:  $K(x_a,x_b)=(x_ax_b+1)^p$. for $p =3$ \\
Note that the python \textit{cvxopt.solvers} cannot solve it by simply implementing the above formula. We need to multiply a scalar to make it convex. We set up the multiplier to be 0.1. 
\end{itemize}

 

%%%%%%%%%%%%
\section{Problem 2}
Due to time limitation, we perform 3-fold cross validation for the training dataset. Below is the error rate for each fold and their total mean error
\begin{table}[H]
	\centering
	\begin{tabular}{c|c|c|c|c}
		\hline
		algorithm&error rate fold1 &error rate fold2 &error rate fold3&mean error\\
		\hline
		\hline
		k=1&0.00886 &0.00812& 0.01040&$ 0.8456\%$\\
		\hline
		k=5& 0.0096& 0.01120& 0.02081&$ 1.3877\%$\\
		\hline
		k=50&0.0904& 0.08086& 0.1& $9.047\%$\\
		\hline
		\hline
		linear kernel& 0.281& 0.123&0.1304&$15.6\%$\\
		\hline
		Gaussian ($\sigma^2=\sqrt{8}$) &4.8038e-03& 8.807e-03& 9.607e-03& $0.77\%$\\
		\hline
		polynomial (p=2)&0.0072& 0.0082& 0.013& $1.034\%$\\
			\hline
		\hline
	\end{tabular}
\end{table}
Also, we can see the confusion matrix for each algorithm 
\begin{itemize}
	\item k-nn, when k=1
	\begin{verbatim}
     y
predict  0   1   2   3   4   5   6   7   8   9
     0 382   0   0   0   0   0   0   0   1   0
     1   0 387   2   0   0   0   0   3   0   0
     2   0   2 389   2   0   0   0   1   0   0
     3   0   1   1 365   0   0   0   0   0   3
     4   2   0   0   0 389   0   0   0   0   2
     5   0   0   0   1   0 374   0   0   2   1
     6   0   0   0   0   0   0 351   0   0   0
     7   0   0   0   2   1   0   0 369   2   0
     8   0   0   0   0   0   0   0   1 358   0
     9   0   0   0   0   1   1   0   0   0 351
	\end{verbatim}
	
	\item k-nn, when k=5
	\begin{verbatim}
     y
 predict 0   1   2   3   4   5   6   7   8   9
     0 383   0   0   0   0   0   0   0   1   0
     1   0 365   2   0   0   0   0   3   0   1
     2   0   8 389   2   0   0   0   0   0   0
     3   0  15   0 365   0   0   0   0   0   5
     4   1   0   0   0 389   0   0   0   0   0
     5   0   1   0   1   0 375   0   0   0   5
     6   0   0   0   0   0   0 351   0   0   0
     7   0   1   1   2   1   0   0 371   2   0
     8   0   0   0   0   0   0   0   0 360   0
     9   0   0   0   0   1   0   0   0   0 346
	\end{verbatim}
	
	\item k-nn, when k=50
	\begin{verbatim}
     y
predict  0   1   2   3   4   5   6   7   8   9
     0 372   0   0   0   0   0   0   0   7   5
     1   0 278   3   7   2   0   0  25   5  12
     2   0  76 388   1   1   0   0   0   3   0
     3   0  23   0 362   0  11   0  22  18  13
     4   7   0   0   0 387   0   0   0   0   9
     5   0   3   0   0   0 359   0   0   6  18
     6   5   5   0   0   0   0 351   0   6   0
     7   0   5   1   0   0   0   0 327  11   0
     8   0   0   0   0   0   0   0   0 301   0
     9   0   0   0   0   1   5   0   0   6 300
	\end{verbatim}
	
	\item SVM, linear kernel
	\begin{verbatim}
	     y
	predict   0   1   2   3   4   5   6   7   8   9
	     0 367   0   0   0   0   0   0   0  15   4
	     1   1 265   3   7   2   0   0  39   3  15
	     2   0  87 388   1   2   0   0   1   7   0
	     3   0  23   0 362   0  23   0  22  28  29
	     4   8   0   0   0 385   0   0   0   0  16
	     5   0   3   0   0   0 338   0   0   8  13
	     6   8   5   0   0   0   2 351   0  10   0
	     7   0   6   1   0   0   0   0 312  11   0
	     8   0   0   0   0   0   0   0   0 272   0
	     9   0   1   0   0   2  12   0   0   9 280
	\end{verbatim}
	
	\item SVM, Gaussian Kernel
	\begin{verbatim}
	     y
	predict  0   1   2   3   4   5   6   7   8   9
	     0 383   0   0   0   0   0   0   0   1   0
	     1   0 379   2   0   0   0   0   0   0   0
	     2   0   6 389   2   0   0   0   0   0   0
	     3   0   5   0 366   0   0   0   0   0   0
	     4   1   0   0   0 390   0   0   0   0   0
	     5   0   0   0   1   0 375   0   0   0   0
	     6   0   0   0   0   0   0 351   0   0   0
	     7   0   0   1   1   1   0   0 374   1   0
	     8   0   0   0   0   0   0   0   0 361   0
	     9   0   0   0   0   0   0   0   0   0 357
	     
	\end{verbatim}
	
	\item SVM, Polynomial Kernel
	\begin{verbatim}
	     y
	 predict 0   1   2   3   4   5   6   7   8   9
	     0 382   0   0   0   0   0   0   0   1   0
	     1   0 368   2   0   0   0   0   0   0   0
	     2   0   8 389   1   0   0   0   0   0   0
	     3   0  12   0 366   0   1   0   0   0   1
	     4   1   0   0   0 389   0   0   0   0   0
	     5   0   0   0   0   0 370   0   0   0   0
	     6   0   0   0   0   0   0 351   0   0   0
	     7   0   2   1   3   1   0   0 374   1   0
	     8   1   0   0   0   0   0   0   0 361   0
	     9   0   0   0   0   1   4   0   0   0 356
	\end{verbatim}
	
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problem 3}
 \begin{figure}[H]
 	\centering
 	\subfloat[]{\includegraphics[trim=0cm 0cm 0cm 0cm, clip, width=3.5in]{digit1}}
 	\subfloat[]{\includegraphics[trim=0cm 0cm 0cm 0cm, clip, width=3.5in]{digit2}}

 	\caption{linear kernel. (a) from top(three) to bottom is: 0,1,2,3,4,5. (b) from top (three) to bottom is 6,7,8,9 }
 	\label{fig:pattern1}
 \end{figure}
 %%%%%%%%%%%%%%%%%%%%
  \begin{figure}[H]
 	\centering
 	\subfloat[]{\includegraphics[trim=0cm 0cm 0cm 0cm, clip, width=3.5in]{digit5}}
 	\subfloat[]{\includegraphics[trim=0cm 0cm 0cm 0cm, clip, width=3.5in]{digit6}}
 	
 	\caption{Guassian Kernel ($\sigma^2=\sqrt{8})$. (a) from top (three) to bottom is: 0,1,2,3,4,5. (b) from top (three) to bottom is 6,7,8,9 }
 	\label{fig:pattern1}
 \end{figure}
 
 %%%%%%%%%%%%%%%%%%%%%%%
   \begin{figure}[H]
   	\centering
   	\subfloat[]{\includegraphics[trim=0cm 0cm 0cm 0cm, clip, width=3.5in]{digit3}}
   	\subfloat[]{\includegraphics[trim=0cm 0cm 0cm 0cm, clip, width=3.5in]{digit4}}
   	
   	\caption{Polynomial Kernel ($p=2$. (a) from top (three) to bottom is: 0,1,2,3,4,5. (b) from top (three) to bottom is 6,7,8,9 }
   	\label{fig:pattern1}
   \end{figure}
   
   
 
 
 %%%%%%%%%%%%%%%%%%

 Above the is the example instance corresponding to the support vector for each digit using different kernels:linear,Gaussian and polynomial. We somehow can tell that it is handwriting from digit 0-9. 
 
\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		kernel&total number of support vectors\\
		\hline
		linear &1486\\
		\hline 
		Gaussian ($\sigma^2=\sqrt{8}$) & 884\\
		\hline
	Polynomial ($p=2$) & 986\\
	\hline
	\end{tabular}
\end{table}
Just by looking at the number of support vectors, Gaussian kernel might be have a better result since it has relatively small support vectors compared to other kernels.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problem 4}


Knn algorithm assumes\textbf{ locally} clustered data structure while SVM assumes \textbf{globally} data structure. When the data tends to be clustered, then k-nn works better. When the data has some overlapping clusteres, k-nn will definitely failed. However, SVM might still work and we have to chose SVM on that case.\\

Moreover, we found that both methods are highly affected by their tuning parameters (ex: k in K-nn and $\sigma^2$ in Gaussian Kernel). Based on all the overall errors we got in part 2, it's hard to say which one SVM or k-nn is better since different tuning parameters and kernels give us quiet distinct results. 

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
type&level1&level2&level3\\
\hline
k-nn& k=1&k=5&k=50\\
\hline
SVM& linear kernel& Gaussian ($\sigma^2=\sqrt{8}$)&Gaussian($\sigma^2=5$)\\
\hline
SVM Polynomial& $p=2$& $p=3$&$p=5$\\
\hline
\end{tabular}
\end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.6\linewidth, height=7.5cm]{knnvsSVM}
\caption{}
\label{fig:larynx}
\end{figure}
 
we can see that some tuning parameters of knn and SVM can have big error rate (k-nn for k=50 and linear kernel in SVM). The other parameters have pretty good and low error rates. However, we need to be careful of overfitting, especially for k-nn. \\

Also, the size of samples also play an important role in k-nn and SVM algorithms. When sample size is relatively small, it looks that k-nn (k=5) will be largely affected. And when sample size increases, the mean error rates for all the three different methods (knn for k=1,5 and SVM (Guassian)) are reduced. So k-nn and SVM doesn't have a big difference in large sample size but k-nn (k=5) is sufficiently bad given a small sample size. (shown in Figure Below)

\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\linewidth, height=7.5cm]{size}
	\caption{}
	\label{fig:larynx}
\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problem 5}
The predictions of each algorithm are shown below (row by row). We also save the predictions on .csv files. 
\begin{itemize}
	\item K-nn, when k=1\\
	\begin{scriptsize}

	
	
	\begin{verbatim}
	[1] 7 1 0 6 6 5 6 3 5 1 0 6 6 3 8 4 8 8 7 5 0 6 9 8 9 1 1 2 0 3 4 1 7 0 9 9 6 4 9 6 8 4 0 8 9 8 7 8 0 2 4 0 1
	[54] 3 3 9 0 3 0 9 4 0 0 6 8 4 5 1 1 4 9 8 3 6 3 6 9 0 4 5 8 7 6 3 1 1 8 0 0 5 7 1 8 3 0 9 2 0 9 1 9 1 3 5 6 6
	[107] 3 1 6 2 6 8 5 8 3 4 2 4 2 3 4 5 4 3 0 3 1 1 1 6 2 0 7 8 5 5 2 1 2 9 8 0 1 4 6 2 7 4 2 8 9 4 2 0 8 0 6 0 0
	[160] 8 7 3 7 7 3 9 7 8 6 4 7 2 0 1 8 8 7 4 7 5 7 7 7 1 2 5 1 2 3 5 9 0 6 1 1 6 5 2 1 3 3 7 7 1 0 3 7 4 4 5 2 5
	[213] 1 0 8 2 8 7 2 2 6 4 7 3 0 9 7 9 8 7 4 9 9 8 1 8 6 9 0 6 2 4 2 0 8 5 2 8 4 7 0 5 9 7 6 0 0 7 7 3 2 0 8 1 3
	[266] 3 9 9 7 9 3 9 6 2 7 6 6 7 0 9 2 4 3 0 7 2 0 5 2 2 1 9 4 9 9 8 4 5 1 9 6 8 9 3 9 9 9 4 9 7 0 4 1 6 6 6 0 5
	[319] 8 3 5 9 2 2 3 2 3 9 4 8 9 6 7 7 1 2 8 2 9 1 0 7 2 8 2 4 3 1 7 3 3 9 4 7 7 9 7 3 7 6 2 4 3 0 1 0 9 6 4 1 2
	[372] 7 8 0 1 4 7 1 7 4 1 8 7 2 1 3 6 1 2 9 3 4 0 0 9 3 8 6 6 1 9 3 3 1 7 6 4 1 5 7 6 8 6 5 4 2 6 0 0 2 9 7 0 9
	[425] 2 4 5 3 9 2 6 1 9 1 3 6 9 1 4 3 7 4 6 5 0 0 6 8 7 2 7 5 7 8 7 2 1 5 3 1 6 9 0 8 4 0 4 7 0 2 1 0 7 9 7 3 4
	[478] 4 3 7 1 7 2 2 4 7 3 0 8 1 1 2 0 8 0 9 0 0 9 6 1 6 6 0 7 9 4 0 4 1 8 4 8 8 9 9 2 3 9 2 7 5 4 8 3 9 8 6 2 8
	[531] 1 5 1 4 0 7 6 5 8 1 6 3 2 6 1 0 7 0 8 2 0 1 9 9 4 2 1 6 2 1 9 8 6 2 6 5 8 5 9 1 2 9 3 5 8 8 8 2 8 2 6 3 6
	[584] 7 7 4 3 4 0 9 0 1 2 8 8 9 8 4 0 5 1 5 4 8 2 4 2 3 7 2 5 7 1 7 9 0 1 2 2 7 1 9 6 1 1 4 5 6 6 1 7 1 4 3 7 1
	[637] 1 5 4 3 9 4 1 1 5 5 2 7 3 2 6 7 1 7 6 1 1 9 2 3 8 0 8 0 7 7 5 4 2 2 2 0 0 2 6 7 5 7 0 6 9 7 0 4 2 5 3 3 5
	[690] 9 2 0 1 3 8 0 8 7 9 9 1 8 9 1 8 2 0 0 0 6 8 9 2 7 2 3 4 9 3 1 6 4 9 0 0 1 6 2 3 3 6 7 3 2 4 1 3 4 1 7 7 0
	[743] 7 2 8 9 5 5 4 8 7 4 0 0 3 3 3 3 8 6 4 6 7 9 4 2 2 7 9 1 3 3 2 1 1 7 8 4 1 4 7 3 5 5 6 2 2 0 2 5 8 1 7 4 9
	[796] 7 3 8 9 9 3 2 8 0 4 9 4 5 4 8 7 0 5 1 6 1 6 0 8 4 3 1 7 7 1 0 5 1 0 8 1 4 0 1 1 5 3 7 6 6 0 2 2 8 6 2 2 9
	[849] 1 6 3 2 8 9 6 8 5 0 7 6 1 9 4 2 3 3 0 4 7 5 1 3 5 0 4 2 2 3 8 2 2 3 9 0 1 1 2 6 8 1 3 5 4 6 7 7 0 3 6 0 5
	[902] 9 1 7 4 2 6 9 8 5 1 2 2 5 6 6 7 1 2 8 0 8 3 6 5 4 6 1 6 4 1 2 4 5 1 5 4 1 0 9 8 5 9 6 3 3 0 9 7 5 1 6 7 7
	[955] 2 9 6 8 3 2 0 5 9 0 6 6 3 2 6 9 9 0 3 5 9 2 7 7 3 2 6 5 7 7 9 6 2 8 5 7 5 2 6 7 1 7 6 6 1 1 5 2 8 4 8 1 1
	[1008] 5 7 0 9 5 5 0 2 2 9 6 7 0 5 2 5 3 8 2 9 9 5 5 9 7 5 9 9 5 1 5 4 8 4 1 3 8 4 8 8 7 3 8 4 4 7 2 4 7 1 4 7 1
	[1061] 8 3 0 4 2 2 9 2 1 3 8 9 7 5 6 2 0 3 1 7 8 6 8 2 7 6 4 9 2 9 9 7 1 4 1 0 0 3 1 9 9 5 7 3 2 6 2 4 1 5 5 6 8
	[1114] 2 0 2 0 5 1 0 5 0 4 5 5 5 8 0 2 5 1 9 3 2 1 9 9 6 3 5 4 8 0 8 3 8 2 7 4 4 4 5 2 0 3 9 0 7 5 6 8 1 4 1 3 5
	[1167] 7 8 5 8 7 8 9 1 2 6 9 6 5 7 6 6 7 0 3 2 5 5 1 4 7 2 6 9 6 4 7 0 4 8 1 4 9 8 9 0 0 1 8 5 9 6 3 8 1 1 6 0 5
	[1220] 9 1 9 4 2 5 7 1 5 4 1 6 8 6 0 1 3 7 2 7 2 4 9 6 4 4 7 9 3 1 7 4 8 5 3 8 0 2 5 0 0 9 5 2 7 5 0 9 8 0 5 5 2
	[1273] 5 7 0 8 8 7 1 0 2 8 4 5 4 7 8 8 8 4 6 1 0 7 0 3 4 1 4 0 5 8 7 9 6 5 8 7 7 0 6 9 0 8 9 6 7 3 2 6 4 1 3 1 5
	[1326] 3 0 1 3 3 0 8 9 2 4 1 5 3 6 7 2 2 2 2 1 2 3 4 7 7 8 1 6 6 7 2 7 0 9 6 7 6 7 8 0 2 9 0 4 9 5 6 1 9 4 0 7 9
	[1379] 6 3 9 3 7 6 5 1 1 5 9 2 5 0 5 6 6 0 3 8 4 4 4 0 5 7 0 8 6 0 0 4 7 0 6 5 2 0 6 2 8 7 0 1 3 5 9 6 4 4 1 5 6
	[1432] 4 4 3 8 8 9 6 6 4 5 6 7 5 5 2 9 7 6 9 3 0 4 3 4 6 7 9 3 1 5 4 2 6 3 3 8 9 0 4 8 0 5 8 0 5 1 2 1 4 8 1 4 2
	[1485] 6 0 6 8 0 2 3 0 6 8 4 9 4 5 9 9 4 5 7 1 3 6 7 1 8 9 4 6 2 9 6 9 5 1 7 4 3 0 0 8 3 7 0 4 9 4 0 1 6 8 1 8 6
	[1538] 9 3 0 2 0 4 6 8 2 3 1 6 6 4 4 2 4 0 5 9 4 5 1 6 1 1 3 0 4 2 6 0 3 0 4 8 2 6 7 7 4 2 0 9 4 0 9 2 5 0 4 2 1
	[1591] 9 9 3 1 0 2 7 9 1 3 7 4 7 1 9 0 3 2 6 6 6 2 4 9 6 2 8 5 5 4 7 8 6 2 0 5 8 0 6 3 4 4 0 6 1 3 0 8 4 6 0 7 8
	[1644] 2 3 3 9 8 1 5 4 6 3 4 4 1 4 0 3 3 9 4 4 3 8 2 7 3 3 8 4 2 5 2 8 3 8 8 2 8 3 9 0 6 8 1 0 2 0 1 6 1 7 9 2 9
	[1697] 1 6 5 3 6 2 0 0 4 6 9 7 6 5 4 3 7 2 5 8 8 6 5 7 4 0 6 0 3 6 3 0 9 6 2 6 3 7 8 8 1 0 5 0 1 6 2 9 3 8 4 4 9
	[1750] 5 1 4 3 5 7 1 1 2 4 2 7 9 9 4 2 1 6 0 4 3 4 0 1 5 0 8 9 2 5 0 5 5 6 2 4 3 6 3 9 0 7 5 6 7 7 8 7 2 4 4 2 8
	[1803] 8 5 0 6 8 0 5 7 5 6 1 0 2 2 5 2 7 9 9 1 2 0 7 1 8 9 7 1 7 1 5 3 7 7 0 1 2 3 8 7 2 9 9 4 6 4 7 1 9 2 0 1 8
	[1856] 8 1 7 2 1 6 8 6 4 5 7 0 1 7 6 9 5 2 1 0 5 0 5 1 5 5 5 6 6 5 9 8 9 7 4 1 7 2 1 7 5 9 9 3 2 0 1 2 2 3 6 6 8
	[1909] 9 8 5 3 2 3 0 1 1 9 5 3 3 3 0 9 6 6 2 8 2 3 4 7 6 5 6 6 5 0 3 8 4 2 6 4 0 3 6 7 8 8 0 0 4 2 7 0 2 4 2 3 0
	[1962] 6 4 5 9 4 0 3 6 3 6 5 1 2 8 4 4 4 1 2 7 2 6 1 1 7 6 8 4 1 7 7 1 4 6 3 1 5 4 1 3 9 1 4 2 5 9 6 9 9 9 9 2 7
	[2015] 2 8 2 7 1 7 5 5 9 5 5 7 1 2 7 5 7 7 5 1 5 6 9 8 6 0 9 8 8 1 3 9 9 6 8 0 7 6 0 0 1 1 9 4 9 7 9 9 0 0 0 9 6
	[2068] 0 2 7 2 5 6 5 7 0 5 9 8 1 7 8 2 8 5 8 8 5 0 2 4 3 6 1 8 8 4 9 2 6 9 9 4 4 6 3 8 5 6 7 9 4 7 3 8 4 5 5 9 3
	[2121] 1 0 6 3 6 4 0 3 3 7 1 5 9 2 8 8 7 3 3 7 0 1 2 1 4 7 7 1 5 4 1 7 8 9 1 7 4 4 7 2 9 7 1 5 7 3 4 9 2 9 3 3 8
	[2174] 7 2 8 0 5 7 0 5 1 3 4 3 8 0 6 1 0 3 0 5 5 0 3 8 1 8 4 0 2 2 3 7 8 3 7 8 3 6 5 1 5 4 0 4 7 2 1 8 4 0 2 6 5
	[2227] 9 8 6 8 5 5 1 1 4 0 9 4 2 6 5 3 6 8 4 3 7 6 6 9 2 6 8 1 1 8 7 0 9 0 7 0 1 6 9 5 1 3 0 4 1 0 5 5 4 5 5 5 3
	[2280] 8 1 2 7 2 1 5 4 0 7 0 6 3 5 1 3 7 1 8 0 6 6 4 7 7 7 1 5 7 4 0 7 5 1 3 2 0 4 4 6 9 8 0 4 5 8 2 3 0 3 0 2 3
	[2333] 2 4 9 4 5 0 5 2 0 8 7 3 8 3 5 5 4 0 4 6 0 4 3 9 0 2 8 9 4 7 8 0 9 9 4 1 5 7 6 1 4 2 7 5 0 6 4 3 5 6 1 8 4
	[2386] 8 2 2 1 5 0 9 2 4 6 8 1 5 5 3 1 6 1 0 2 3 9 6 2 3 5 7 8 9 4 5 0 3 9 4 4 0 6 3 4 3 5 8 4 1 9 1 9 6 3 9 6 9
	[2439] 8 3 1 1 0 9 3 3 7 0 6 5 9 8 8 0 3 9 7 0 9 2 4 1 8 6 9 2 2 1 9 8 3 3 0 5 9 7 8 0 5 2 4 2 9 4 8 3 9 2 3 0 4
	[2492] 5 7 5 2 1 3 8 8 4 4 0 1 8 0 0 9 4 4 5 6 3 0 7 4 5 0 3 6 3 4 7 7 9 1 0 5 8 6 4 1 6 3 8 3 1 9 2 8 2 4 1 9 0
	[2545] 0 2 7 7 3 8 3 6 4 5 0 5 5 4 8 5 3 8 1 4 1 9 9 7 2 6 5 1 6 3 4 9 7 0 1 3 9 8 8 4 8 7 8 3 8 4 1 2 6 9 3 9 2
	[2598] 0 1 2 2 5 2 6 3 5 8 0 0 8 8 2 1 4 1 4 0 9 4 0 4 7 1 9 4 6 1 0 1 8 8 3 1 1 4 2 3 1 4 4 4 7 4 8 1 0 3 4 1 4
	[2651] 2 3 9 9 2 2 8 1 1 9 3 8 3 3 3 2 7 5 1 3 4 2 5 4 8 0 2 5 5 9 7 6 9 2 7 7 4 4 0 2 3 9 7 4 8 4 1 7 4 4 0 3 1
	[2704] 8 6 2 0 4 0 8 4 7 8 9 6 1 5 8 1 4 4 9 1 0 4 5 4 3 5 2 9 4 7 7 6 6 7 2 5 9 5 8 3 2 7 0 9 4 5 9 8 6 8 2 6 0
	[2757] 1 8 4 5 7 1 0 1 6 6 7 5 1 7 6 3 4 2 3 6 6 7 3 6 9 8 5 3 6 0 0 8 9 3 7 7 5 4 1 3 1 2 8 4 7 3 8 6 4 6 7 2 9
	[2810] 4 1 4 0 6 4 3 6 3 9 1 7 0 7 8 6 3 8 8 3 9 6 0 2 0 5 0 7 1 4 6 1 7 5 6 2 9 6 0 2 9 2 7 4 2 2 4 0 9 2 1 6 5
	[2863] 4 2 7 1 0 0 1 3 8 3 2 9 4 7 9 3 1 6 4 6 2 4 3 1 7 5 9 1 4 0 0 3 5 0 2 6 8 8 7 4 4 5 0 2 7 4 3 8 3 0 1 8 5
	[2916] 6 2 2 7 0 8 4 7 4 7 8 5 0 9 9 7 5 9 7 7 5 7 9 7 5 9 7 2 1 2 8 0 2 8 0 8 2 0 4 2 5 6 3 7 1 1 2 9 8 2 6 7 4
	[2969] 6 6 9 5 4 2 7 5 8 8 2 1 3 5 9 9 8 4 8 3 7 7 8 9 7 6 0 1 9 5 0 6 0 0 3 4 2 0 3 2 2 5 8 6 5 3 2 6 4 5 7 6 8
	[3022] 1 2 1 3 9 4 5 1 7 4 7 0 6 5 1 3 6 5 4 2 5 9 2 7 4 7 5 7 4 5 6 1 8 2 9 9 4 1 1 6 7 2 6 5 8 7 6 9 6 0 4 9 8
	[3075] 9 7 1 1 2 5 9 3 4 6 7 0 7 0 9 2 2 8 6 8 9 9 3 2 2 9 9 8 4 6 5 2 7 3 7 2 0 7 7 5 4 6 1 3 6 7 7 4 2 3 5 3 6
	[3128] 9 1 3 1 1 9 2 1 0 1 9 4 5 9 7 6 2 7 1 4 0 5 9 9 8 7 7 6 4 7 2 4 2 4 8 5 9 6 5 8 5 8 8 4 3 9 5 8 4 8 7 0 0
	[3181] 2 2 0 3 6 6 4 8 4 0 1 7 2 3 6 9 2 4 6 5 5 8 3 1 5 0 2 8 4 2 5 9 7 1 0 0 8 4 9 3 3 3 2 8 3 0 6 9 2 9 6 4 3
	[3234] 4 3 6 3 0 4 7 5 2 8 7 6 0 4 2 3 4 5 9 0 6 9 1 2 8 1 0 8 4 3 5 8 9 5 8 5 2 3 6 2 8 4 1 2 1 2 4 8 1 9 7 0 6
	[3287] 8 6 7 6 7 0 9 7 3 3 2 6 0 6 7 6 3 0 2 7 2 3 8 5 6 8 4 0 7 7 2 8 0 5 6 9 5 2 2 9 1 9 2 3 0 4 1 5 2 0 1 4 0
	[3340] 3 9 6 7 1 2 3 6 7 6 5 8 5 6 2 2 3 6 6 6 7 7 2 4 9 6 4 0 8 4 8 7 8 5 7 4 2 6 7 7 2 3 6 2 3 7 6 7 2 8 2 9 7
	[3393] 2 3 0 7 2 1 9 0 3 7 6 0 8 1 5 2 9 5 3 9 8 5 2 9 2 5 1 6 8 3 2 8 9 7 0 1 2 0 0 8 3 5 7 0 9 9 7 9 1 4 1 2 5
	[3446] 9 0 2 4 6 1 0 0 9 4 0 7 7 6 5 2 5 1 2 9 5 4 5 8 8 9 7 5 9 1 6 7 7 7 8 5 3 2 3 6 0 1 9 8 0 7 2 1 5 1 1 4 0
	[3499] 7 7 4 9 5 5 1 4 4 3 3 9 2 7 7 1 4 0 3 5 6 0 8 4 0 8 5 6 5 7 3 0 4 1 5 7 3 2 6 6 7 7 1 2 2 6 9 0 7 8 1 0 4
	[3552] 1 7 8 3 9 2 7 0 1 8 6 2 8 5 6 9 7 7 4 4 5 0 8 7 7 0 2 3 7 6 4 8 3 1 3 6 2 9 3 7 8 5 6 4 9 1 3 0 3 4 3 0 2
	[3605] 7 9 0 7 7 3 5 5 3 7 2 3 1 7 7 8 4 0 6 7 4 0 0 5 1 7 1 1 6 6 8 8 9 9 8 7 3 4 4 4 3 9 2 4 3 1 2 3 3 1 0 1 6
	[3658] 3 4 6 7 3 4 5 8 2 7 6 0 9 6 0 1 7 1 8 9 8 7 1 5 4 4 8 1 4 1 6 6 0 3 5 7 2 7 5 4 1 2 0 1 9 0 2 6 4 8 9 3 3
	[3711] 0 3 5 9 4 3 0 3 7 7 0 3 3 3 1 1 1 3 6 8 4 2 7 6 4 1 9 2 6 3 9 0 5 4 5 1 7
	\end{verbatim}

 	\end{scriptsize}
	\item K-nn, when k=5\\
	\begin{scriptsize}
		\begin{verbatim}
		   [1] 7 1 0 6 6 5 6 3 5 1 0 6 6 3 8 4 8 8 7 5 0 6 9 8 9 1 1 2 0 3 4 1 7 0 9 9 6 4 9 6 8 4 0 8 9 8
		   [47] 7 8 0 2 4 0 3 3 3 9 0 3 0 9 4 0 0 6 8 4 5 1 1 4 9 8 3 6 3 6 9 0 4 5 8 7 6 3 1 1 8 0 0 5 7 1
		   [93] 8 3 0 9 2 0 9 1 9 1 3 5 6 6 3 1 6 2 6 8 5 8 3 4 2 4 2 3 4 5 4 2 0 3 1 1 1 6 2 0 7 8 5 5 2 1
		   [139] 2 9 8 0 1 4 6 2 7 4 2 8 9 4 2 4 8 0 6 0 0 8 7 3 7 7 3 9 7 8 6 4 7 2 0 1 8 8 7 4 7 5 7 7 7 1
		   [185] 2 5 1 2 3 5 9 0 6 1 1 6 5 2 1 3 3 7 7 1 0 3 7 4 4 5 2 5 1 0 8 2 8 7 2 2 6 4 7 3 0 9 7 9 8 7
		   [231] 4 9 9 8 1 8 6 9 0 6 2 4 2 0 8 5 2 8 4 7 0 5 9 7 6 0 0 7 7 3 2 0 8 1 3 3 9 9 7 9 3 9 6 2 7 6
		   [277] 6 7 0 9 2 4 3 0 7 2 0 5 2 2 1 9 4 9 9 8 4 5 1 9 6 8 9 3 9 9 9 4 9 7 0 4 1 6 6 6 0 5 8 3 5 9
		   [323] 2 2 3 2 3 9 4 8 9 6 7 7 2 2 8 2 9 1 0 7 2 8 2 4 3 1 7 3 3 9 4 7 7 9 7 3 7 6 2 4 3 0 1 0 9 6
		   [369] 4 1 2 7 8 0 1 4 7 1 7 4 1 8 7 2 1 3 6 1 2 9 3 4 0 0 9 3 8 6 6 1 9 3 3 1 7 6 9 3 5 7 6 8 6 5
		   [415] 4 2 6 0 0 2 9 7 0 9 2 4 5 3 9 2 6 1 9 1 3 6 9 1 4 3 7 4 6 5 0 0 6 8 7 2 7 5 7 8 7 2 1 5 3 1
		   [461] 6 9 0 8 4 0 4 7 0 2 1 0 7 9 7 3 4 4 3 7 1 7 2 2 4 7 3 0 8 1 1 2 0 8 0 9 0 0 9 6 1 6 6 0 7 9
		   [507] 4 0 4 1 8 4 8 8 9 9 2 3 9 2 7 5 4 8 3 9 8 6 2 8 1 5 1 4 0 7 6 5 8 1 6 3 2 6 1 0 7 0 8 2 0 1
		   [553] 9 9 4 2 1 6 2 1 9 8 6 2 6 5 8 5 9 1 2 9 3 5 8 8 8 2 8 2 6 3 6 7 7 4 3 4 0 9 0 1 2 8 8 9 8 4
		   [599] 0 5 1 5 4 8 2 4 2 3 7 2 5 7 1 7 9 0 1 2 2 7 1 9 6 1 1 4 5 6 6 1 7 1 4 3 7 1 1 5 4 3 9 4 1 1
		   [645] 5 5 2 7 3 2 6 7 1 7 6 1 1 9 2 3 8 0 8 0 7 7 5 4 2 2 2 0 0 2 6 7 5 7 0 6 9 7 0 4 2 5 3 3 5 9
		   [691] 2 0 1 3 8 0 8 7 9 9 1 8 9 2 8 2 0 0 0 6 8 9 2 7 2 3 4 9 3 1 6 4 9 0 0 1 6 2 3 3 6 7 3 2 4 1
		   [737] 3 4 1 7 7 0 7 2 8 9 5 5 4 8 7 4 0 0 3 3 3 3 7 6 4 6 7 9 4 2 2 7 9 1 3 3 2 1 1 7 8 4 1 4 7 3
		   [783] 5 5 6 2 2 0 2 5 8 1 7 4 9 7 3 8 9 9 3 2 8 0 4 9 4 5 4 8 7 0 5 1 6 1 6 0 8 4 3 1 7 7 1 0 5 1
		   [829] 0 8 1 4 0 1 1 5 3 7 6 6 0 2 2 8 6 2 2 9 3 6 3 2 8 9 6 8 5 0 7 6 1 9 4 2 3 3 0 4 7 5 1 3 5 0
		   [875] 4 2 2 3 8 2 2 3 9 0 1 1 2 6 8 1 3 5 4 6 7 7 0 3 6 0 5 9 1 7 4 2 6 9 8 5 1 2 2 5 6 6 7 1 2 8
		   [921] 0 8 3 6 5 4 6 1 6 4 1 2 4 5 1 5 4 1 0 9 8 5 9 6 3 3 0 9 7 5 1 6 7 7 2 9 6 8 3 2 0 5 9 0 6 6
		   [967] 3 2 6 9 9 0 3 5 9 2 7 7 3 2 6 5 7 7 9 6 2 8 5 7 5 2 6 7 1 7 6 6 1 1 5 2 8 4 8 1 1 5 7 0 9 5
		   [1013] 5 0 2 2 9 6 7 0 5 2 5 3 8 2 9 9 5 5 9 7 5 9 9 5 1 5 4 8 4 1 3 8 4 8 8 7 3 8 4 4 7 2 4 7 1 4
		   [1059] 7 1 8 3 0 4 2 2 5 2 1 3 8 9 7 5 6 2 0 3 1 7 8 6 8 2 7 6 4 9 2 9 9 7 1 4 1 0 0 3 1 9 9 5 7 3
		   [1105] 2 6 2 4 1 5 5 6 8 2 0 2 0 5 1 0 5 0 4 5 5 5 8 0 2 5 1 9 3 2 1 9 9 6 3 5 4 8 0 8 3 8 2 7 4 4
		   [1151] 4 5 2 0 3 9 0 7 5 6 8 1 4 1 3 5 7 8 5 8 7 8 9 1 2 6 9 6 5 7 6 6 7 0 3 2 5 5 1 4 7 2 6 9 6 4
		   [1197] 7 0 4 8 1 4 9 8 9 0 0 1 8 5 9 6 3 8 1 1 6 0 5 9 1 9 4 2 5 7 1 5 4 1 6 8 6 0 1 3 7 2 7 2 4 9
		   [1243] 6 4 4 7 9 3 1 7 4 8 5 3 8 0 2 5 0 0 9 5 2 7 5 0 9 8 0 5 5 2 5 7 0 8 8 7 1 0 2 8 4 5 4 7 8 8
		   [1289] 8 4 6 1 0 7 0 3 4 1 4 0 5 8 7 9 6 5 8 7 7 0 6 9 0 8 9 6 7 3 2 6 4 1 3 1 5 3 0 1 3 3 0 8 9 2
		   [1335] 4 9 5 3 6 7 2 2 2 2 1 2 3 4 7 7 8 1 6 6 7 2 7 0 9 6 7 6 7 8 0 2 9 0 4 9 5 6 1 9 4 0 7 9 6 3
		   [1381] 9 3 7 6 5 1 1 5 9 2 5 0 5 6 6 0 3 8 4 4 4 0 5 7 0 8 6 0 0 4 7 0 6 5 2 0 6 2 8 7 0 1 3 5 9 6
		   [1427] 4 4 3 5 6 4 4 3 8 8 9 6 6 4 5 6 7 5 5 2 9 7 6 9 3 0 4 3 4 6 7 9 3 1 5 4 2 6 3 3 8 9 0 4 8 8
		   [1473] 5 8 0 5 1 2 1 4 8 1 4 2 6 0 6 8 0 2 3 0 6 8 4 9 4 5 9 9 4 5 7 1 3 6 7 1 8 9 4 6 2 9 6 9 5 1
		   [1519] 7 4 3 0 0 8 3 7 0 4 9 4 0 1 6 8 1 8 6 9 3 0 2 0 4 6 8 2 3 1 6 6 4 4 2 4 0 5 9 4 5 1 6 1 1 3
		   [1565] 0 4 2 6 0 3 0 4 8 2 6 7 7 4 2 0 9 4 0 9 2 5 0 4 2 3 9 9 3 1 0 2 7 9 1 3 7 4 7 1 9 0 3 2 6 6
		   [1611] 6 2 4 9 6 2 8 5 5 4 7 8 6 2 0 5 8 0 6 3 4 4 0 6 1 3 0 8 4 6 0 7 7 2 3 3 9 8 1 5 4 6 3 4 4 1
		   [1657] 4 0 3 3 9 4 4 3 8 2 7 3 3 8 4 2 5 2 8 3 8 8 2 8 3 9 0 6 8 1 0 2 0 1 6 1 7 9 2 9 1 6 5 3 6 2
		   [1703] 0 0 1 6 9 7 6 5 4 3 7 2 5 8 8 6 5 7 4 0 6 0 3 6 3 0 9 6 2 6 3 7 8 8 1 0 5 0 1 6 2 9 3 8 4 4
		   [1749] 9 5 1 4 3 5 7 1 1 2 4 2 7 9 9 4 2 1 6 0 4 3 4 0 1 5 0 8 9 2 5 0 5 5 6 2 4 1 6 3 9 0 7 5 6 7
		   [1795] 2 8 7 2 4 4 2 8 8 5 0 6 8 0 5 7 5 6 1 0 2 2 5 2 7 5 9 1 2 0 7 1 8 9 7 1 7 1 5 3 7 7 0 1 2 3
		   [1841] 8 7 2 9 9 4 6 4 7 1 9 2 0 1 8 8 1 7 2 1 6 8 6 4 5 7 0 1 7 6 9 5 2 1 0 5 0 5 1 5 5 5 6 6 5 9
		   [1887] 8 9 7 4 1 7 2 1 7 5 9 9 3 2 0 1 2 2 3 6 6 8 9 8 5 3 2 3 0 1 1 9 5 3 3 3 0 9 6 6 2 8 2 3 4 7
		   [1933] 6 5 6 6 5 0 3 8 4 2 6 4 0 3 6 7 8 8 0 0 4 2 7 0 2 4 2 3 0 6 4 5 9 4 0 3 6 3 6 5 1 2 8 4 4 4
		   [1979] 1 2 7 2 6 1 1 7 6 8 4 1 7 7 1 4 6 3 1 5 4 1 3 9 1 4 2 5 9 6 9 9 9 9 2 7 2 8 2 7 1 7 5 5 9 5
		   [2025] 5 7 1 2 7 5 7 7 5 1 5 6 9 8 6 0 9 8 8 1 3 9 9 6 8 0 7 6 0 0 1 1 9 4 9 7 9 9 0 0 0 9 6 0 2 7
		   [2071] 2 5 6 5 7 0 5 9 8 1 7 8 2 8 5 8 8 5 0 2 4 3 6 1 8 8 4 9 2 6 9 9 4 4 6 3 8 5 6 7 9 4 7 3 8 4
		   [2117] 5 5 9 3 1 0 6 3 6 4 0 3 4 7 1 5 9 2 8 8 7 3 3 7 0 3 2 1 4 7 7 1 5 4 1 7 8 9 1 7 4 4 7 2 9 7
		   [2163] 1 5 7 3 4 9 2 9 3 3 8 7 2 8 0 5 7 0 5 1 3 4 3 8 0 6 1 0 3 0 5 5 0 3 8 1 8 4 0 2 2 3 7 8 3 7
		   [2209] 8 3 6 5 1 5 4 0 4 7 2 1 8 4 0 2 6 5 9 8 6 8 5 5 1 1 4 0 9 4 2 6 5 3 6 8 4 3 7 6 6 9 2 6 8 1
		   [2255] 1 8 7 0 9 0 7 0 1 6 9 5 1 3 0 4 1 0 5 5 4 5 5 5 3 8 1 2 7 2 1 5 4 0 7 0 6 3 5 1 3 7 1 8 0 6
		   [2301] 6 4 7 7 7 1 5 7 4 0 7 5 1 3 2 0 4 4 6 9 8 0 4 5 8 2 3 0 3 0 2 3 2 4 9 4 5 0 5 2 0 8 7 3 8 3
		   [2347] 5 5 4 0 4 6 0 4 3 9 0 2 8 9 4 7 8 0 9 9 4 1 5 7 6 1 4 2 7 5 0 6 4 3 5 6 1 8 4 8 2 2 1 5 0 9
		   [2393] 2 4 6 8 1 5 5 3 1 6 1 0 2 3 9 6 2 3 5 7 8 9 4 5 0 3 9 4 4 0 6 3 4 3 5 8 4 1 9 1 9 6 3 9 6 9
		   [2439] 8 3 1 1 0 9 3 3 7 0 6 5 9 8 8 0 3 9 7 0 9 2 4 1 8 6 9 2 2 1 9 8 3 3 0 5 9 7 8 0 5 2 4 2 9 4
		   [2485] 8 3 9 2 3 0 4 5 7 5 1 1 3 8 8 4 4 0 1 8 0 0 9 4 4 5 6 3 0 7 4 5 0 3 6 3 4 7 7 9 1 0 5 8 6 4
		   [2531] 1 6 7 8 3 1 9 2 8 2 4 1 9 0 0 2 7 7 3 8 3 6 4 5 0 5 5 4 8 5 3 8 1 4 1 9 9 7 2 6 5 1 6 3 4 9
		   [2577] 7 0 1 3 9 8 8 4 8 7 8 3 8 4 1 2 6 9 3 9 2 0 1 2 2 5 2 6 3 5 8 0 0 8 8 2 1 4 1 4 0 9 4 0 4 7
		   [2623] 1 9 4 6 1 0 1 8 8 3 1 1 4 2 3 1 4 4 4 7 4 8 1 0 3 4 1 4 2 3 9 9 2 2 8 1 1 9 3 8 3 3 3 2 7 5
		   [2669] 1 3 4 2 5 4 8 0 2 5 5 9 7 6 9 2 7 7 4 4 0 2 3 9 7 4 8 4 1 7 4 4 0 3 1 8 6 2 0 4 0 8 4 7 8 9
		   [2715] 6 1 5 8 1 4 4 9 1 0 4 5 4 3 5 2 9 4 7 7 6 6 7 2 5 9 5 8 3 2 7 0 9 4 5 9 8 6 8 2 6 0 1 8 4 5
		   [2761] 7 1 0 1 6 6 7 5 1 7 6 3 4 2 3 6 6 7 3 6 9 8 5 3 6 0 0 8 9 3 7 7 5 4 1 3 1 2 8 4 7 3 8 6 4 6
		   [2807] 7 2 9 4 1 4 0 6 4 3 6 3 9 1 7 0 7 8 6 3 8 8 3 9 6 0 2 0 5 0 7 1 8 6 1 7 5 6 2 9 6 0 2 9 2 7
		   [2853] 4 2 2 4 0 9 2 1 6 5 4 2 7 1 0 0 1 3 8 3 2 9 4 7 9 3 1 6 4 6 2 4 3 1 7 5 9 1 4 0 0 3 5 0 2 6
		   [2899] 8 8 7 4 4 5 0 2 7 4 3 8 3 0 1 8 5 6 2 2 7 0 8 4 7 4 7 8 5 0 9 9 7 5 9 7 7 5 7 9 7 5 9 7 2 1
		   [2945] 2 8 0 2 8 0 8 2 0 4 2 5 6 3 7 1 1 2 9 8 2 6 7 4 6 6 9 5 4 2 7 5 8 8 2 1 3 5 9 9 8 4 8 3 7 7
		   [2991] 8 9 7 6 0 1 9 5 0 6 0 0 3 4 2 0 3 2 2 5 8 6 5 3 2 6 4 5 7 6 8 1 2 1 3 9 4 5 1 7 4 7 0 6 5 1
		   [3037] 1 6 5 4 2 5 9 2 7 4 7 5 7 4 5 6 1 8 2 9 9 4 1 1 6 7 2 6 5 8 7 6 9 6 0 7 9 8 9 7 1 1 2 5 9 3
		   [3083] 4 6 7 0 7 0 9 2 2 8 6 8 9 5 3 2 2 9 9 8 4 6 5 2 7 3 7 2 0 7 7 5 4 6 1 3 6 7 7 4 2 3 5 3 6 9
		   [3129] 1 3 1 1 9 2 1 0 1 9 4 5 9 7 6 2 7 1 4 0 5 9 9 8 7 7 6 4 7 2 4 2 4 8 5 9 6 5 8 5 8 8 4 3 9 5
		   [3175] 8 4 8 7 0 0 2 2 0 3 6 6 4 8 4 0 1 7 2 3 6 9 2 4 6 5 5 8 3 1 5 0 2 8 4 2 5 9 7 1 0 0 8 4 9 3
		   [3221] 3 3 2 8 3 0 6 9 2 9 6 4 3 4 3 6 3 0 4 7 5 2 8 7 6 0 4 2 3 4 5 9 0 6 9 1 2 8 1 0 8 4 3 5 8 9
		   [3267] 5 8 5 2 3 6 2 8 4 1 2 1 2 4 8 1 9 7 0 6 8 6 7 6 7 0 9 7 3 3 2 6 0 6 7 6 3 0 2 7 2 3 8 5 6 8
		   [3313] 4 0 7 7 2 8 0 5 6 9 5 2 2 9 2 9 2 3 0 4 1 5 2 0 1 4 0 3 9 6 7 1 2 3 6 7 6 5 8 5 6 2 2 3 6 6
		   [3359] 6 7 7 2 4 9 6 4 0 8 4 8 7 8 5 7 4 2 6 7 7 2 3 6 2 3 7 6 7 2 8 2 9 7 2 3 0 7 2 1 9 0 3 7 6 0
		   [3405] 8 1 5 2 9 5 3 9 8 5 2 9 2 5 1 6 8 3 2 8 9 7 0 1 2 0 0 8 3 5 7 0 9 9 7 9 1 4 1 2 5 9 0 2 4 6
		   [3451] 1 0 0 9 4 0 7 7 6 5 2 5 1 2 9 5 4 5 8 8 9 7 5 9 1 6 7 7 7 8 5 3 2 3 6 0 1 9 8 0 7 2 1 5 1 1
		   [3497] 4 0 7 7 4 9 5 5 1 4 4 3 3 9 2 7 7 1 4 0 3 5 6 0 8 4 0 8 5 6 5 7 3 0 4 1 5 7 3 2 6 6 7 7 1 2
		   [3543] 2 6 9 0 7 8 1 0 4 1 7 8 3 9 2 7 0 1 8 6 2 8 5 6 9 7 7 4 4 5 0 8 7 7 0 2 3 7 6 4 8 3 1 3 6 2
		   [3589] 9 3 7 8 5 6 4 9 1 3 0 3 4 3 0 2 7 9 0 7 7 3 5 5 3 7 2 3 1 7 7 8 4 0 6 7 4 0 0 5 1 7 1 1 6 6
		   [3635] 8 8 9 9 8 7 3 4 4 4 3 9 2 4 3 1 2 3 3 1 0 1 6 3 4 6 7 3 4 5 8 2 7 6 0 9 6 4 1 7 1 8 9 8 7 1
		   [3681] 5 4 4 8 1 4 1 6 6 0 3 5 7 2 7 5 4 1 2 0 1 9 0 2 6 4 8 9 3 3 0 3 5 9 4 3 0 3 7 7 0 3 3 3 1 1
		   [3727] 1 3 6 8 4 2 7 6 4 1 9 2 6 3 9 0 5 4 5 1 7
	
		\end{verbatim}
	\end{scriptsize}
	%%%%%%%%%%%%%%%%%%%
	\item K-nn, when k=50\\
	\begin{scriptsize}
		\begin{verbatim}
		   [1] 7 1 0 6 6 5 6 3 5 1 0 6 6 3 8 4 8 8 1 5 0 6 9 8 9 1 1 2 0 3 4 1 7 0 9 9 6 4 9 6 8 4 0 8 9 8
		   [47] 7 8 0 2 4 0 3 3 3 9 0 3 0 9 4 0 0 6 8 4 5 1 1 4 9 8 3 6 3 6 9 6 4 5 8 7 6 3 1 2 8 0 0 5 7 1
		   [93] 8 3 0 9 2 0 9 1 9 1 3 5 6 6 3 1 6 2 6 8 5 8 3 4 2 4 2 3 4 5 4 2 0 3 1 1 1 6 2 0 7 8 5 5 2 1
		   [139] 2 9 8 0 1 4 6 2 7 4 2 8 9 4 2 4 8 0 6 0 0 8 7 3 7 7 3 9 7 8 6 4 7 2 0 1 8 8 7 4 7 5 7 7 7 1
		   [185] 2 5 1 2 3 5 9 0 6 1 1 6 5 2 2 3 3 7 7 1 0 3 7 4 4 1 2 5 1 0 8 2 8 7 2 2 6 4 7 3 0 9 7 5 8 7
		   [231] 4 9 9 8 1 8 6 9 0 6 2 4 2 0 8 5 2 9 4 7 0 5 9 7 0 0 0 7 7 3 2 0 8 1 3 3 9 9 7 9 3 9 6 2 7 6
		   [277] 6 7 0 9 2 4 3 0 7 2 0 5 2 2 1 9 4 0 9 8 4 5 1 9 6 8 9 3 9 9 9 4 0 7 0 4 1 6 6 6 0 5 8 3 5 9
		   [323] 2 2 3 2 3 9 4 8 9 6 7 7 2 2 8 2 9 1 0 7 2 8 2 4 3 1 7 3 3 9 4 7 7 9 7 3 7 6 2 4 3 0 1 0 1 6
		   [369] 4 1 2 7 8 0 1 4 7 1 7 4 1 1 7 2 1 3 6 1 2 9 3 4 0 0 4 3 8 6 6 1 9 3 3 1 7 6 9 3 5 7 6 8 6 5
		   [415] 4 2 6 0 0 2 9 7 0 9 2 4 5 3 9 2 6 3 9 1 3 6 9 1 4 3 7 4 6 5 0 0 6 8 7 2 7 5 7 8 1 2 3 5 3 2
		   [461] 6 9 0 8 4 0 4 7 0 2 1 0 7 9 7 3 4 4 3 7 1 7 2 2 4 7 3 0 8 6 1 2 0 8 4 9 0 0 9 6 1 6 6 0 7 9
		   [507] 4 0 4 2 7 4 8 8 9 9 2 3 9 2 7 5 4 8 3 9 8 6 2 9 1 5 2 4 0 7 6 5 8 1 6 3 2 6 1 0 7 0 8 2 0 2
		   [553] 9 9 4 2 1 6 2 1 9 8 6 2 6 5 8 5 9 1 2 9 3 5 8 8 8 2 8 2 6 3 6 7 7 4 3 4 0 0 0 1 2 8 8 9 8 4
		   [599] 0 5 1 5 4 8 2 4 2 3 7 2 5 7 1 7 9 0 1 2 2 7 1 9 6 1 2 4 5 6 6 1 7 1 4 3 7 2 1 5 4 3 9 4 1 1
		   [645] 5 5 2 7 3 2 6 7 1 7 6 1 1 9 2 3 8 0 8 0 7 7 5 4 2 2 2 0 0 2 6 7 5 7 0 6 9 7 0 4 2 5 3 3 5 9
		   [691] 2 0 1 3 8 0 8 7 9 9 2 8 9 2 8 2 0 0 0 6 8 9 2 7 2 3 4 9 3 1 6 4 9 0 0 1 6 2 3 3 6 7 3 2 4 1
		   [737] 3 4 1 7 1 0 7 2 8 3 5 5 4 8 7 4 0 0 3 3 3 3 7 6 4 6 7 4 4 2 2 7 9 2 3 3 2 2 1 7 3 4 1 4 7 3
		   [783] 3 5 6 2 2 0 2 5 9 1 7 4 9 7 3 7 9 9 3 2 8 0 4 9 4 5 4 8 7 0 5 1 6 1 6 0 8 4 3 6 7 7 1 0 5 1
		   [829] 0 8 2 4 0 1 1 5 3 7 6 6 0 2 2 8 6 2 2 9 3 6 3 2 8 9 6 8 5 0 7 6 1 9 4 2 3 3 0 4 7 5 1 3 5 0
		   [875] 4 2 2 3 8 2 2 3 5 0 1 1 2 6 8 1 3 5 4 6 7 7 0 3 6 0 5 9 1 7 4 2 6 3 8 5 1 2 2 5 6 6 7 1 2 8
		   [921] 0 8 3 6 5 4 6 1 6 4 1 2 4 5 1 5 4 1 0 9 8 5 9 6 1 3 0 9 1 5 1 6 7 7 2 9 6 8 3 2 0 5 9 0 6 6
		   [967] 3 2 6 9 9 0 3 5 5 2 7 7 3 2 6 5 7 7 1 6 2 8 5 7 5 2 6 7 1 7 6 6 1 1 5 2 7 4 8 3 2 5 7 0 9 5
		   [1013] 5 0 2 2 5 6 7 0 5 2 5 3 8 2 9 5 5 5 9 7 5 9 9 5 1 5 4 3 4 1 3 8 4 8 8 7 3 8 4 4 7 2 4 7 1 4
		   [1059] 7 1 8 3 0 4 2 2 9 2 1 3 8 9 7 5 6 2 0 3 1 7 3 6 8 2 7 6 4 9 2 9 5 7 1 4 1 0 0 3 2 9 9 3 7 3
		   [1105] 2 6 2 4 1 5 5 6 7 2 0 2 0 5 1 0 5 0 4 5 5 5 8 0 2 5 1 9 3 2 2 9 9 6 3 5 4 8 0 8 3 1 2 7 4 4
		   [1151] 4 3 2 0 3 9 0 7 5 6 8 1 4 1 3 5 7 8 5 8 7 8 9 1 2 6 9 6 5 7 6 6 7 0 3 2 5 5 3 4 7 2 6 9 6 4
		   [1197] 7 0 4 8 4 4 9 8 9 0 0 2 8 5 9 6 3 8 1 1 6 0 5 9 3 9 4 2 5 7 1 5 4 2 6 8 6 0 1 3 7 2 7 2 4 9
		   [1243] 6 4 4 7 9 3 1 7 4 8 5 3 8 0 2 5 0 0 9 5 2 7 5 0 9 8 0 5 5 2 5 7 0 8 8 7 1 0 2 7 4 5 4 7 8 7
		   [1289] 8 4 6 1 0 7 0 3 4 1 4 0 5 8 7 9 6 5 8 7 7 0 6 9 0 8 9 6 7 3 2 6 4 1 3 1 5 3 0 1 3 3 0 8 9 2
		   [1335] 4 7 5 3 6 7 2 2 2 2 1 2 3 4 7 7 8 1 6 6 7 2 7 0 9 6 7 6 7 8 0 2 9 0 4 9 5 6 1 9 4 0 7 9 6 3
		   [1381] 9 3 7 6 5 1 1 5 9 2 5 0 5 6 0 0 3 8 4 4 4 0 5 7 0 8 6 0 0 4 7 0 6 5 2 0 6 2 8 7 0 1 3 5 9 6
		   [1427] 4 4 3 5 6 4 4 3 8 8 9 6 6 4 3 6 7 5 5 2 9 7 6 9 3 0 4 3 4 6 7 9 3 1 5 4 2 6 3 3 8 9 0 4 7 0
		   [1473] 5 8 0 5 1 2 1 4 8 1 4 2 6 0 6 8 0 2 3 0 6 3 4 9 4 5 9 9 4 5 7 1 3 6 7 2 8 9 4 6 2 9 6 9 5 2
		   [1519] 7 4 3 0 0 8 3 7 0 4 9 4 0 1 6 8 1 8 6 9 3 0 2 0 4 6 8 2 3 1 6 6 4 4 2 4 0 5 9 4 5 2 6 1 1 3
		   [1565] 0 4 2 6 0 3 0 4 8 2 6 1 7 4 2 0 9 4 0 0 2 5 0 4 2 3 9 9 3 2 0 2 7 9 1 3 7 4 7 1 9 0 3 2 6 6
		   [1611] 6 2 4 9 6 2 8 5 5 4 7 8 6 2 0 5 8 0 6 3 4 4 4 6 2 3 0 3 4 6 0 7 7 2 3 3 9 8 1 5 4 6 3 4 4 2
		   [1657] 4 0 3 3 9 4 4 3 8 2 7 3 3 8 4 2 5 2 8 3 8 8 2 8 3 9 4 6 3 6 0 2 0 1 6 6 7 9 2 9 1 6 5 3 6 2
		   [1703] 0 0 1 6 0 7 6 5 4 3 7 2 5 8 8 6 5 7 4 0 6 0 3 6 3 0 9 6 2 6 3 7 7 8 2 0 5 0 2 6 2 9 3 8 4 4
		   [1749] 9 5 1 4 3 5 7 1 1 2 4 2 7 9 9 4 2 1 6 0 4 3 4 0 3 3 0 3 9 2 5 0 5 5 6 2 4 1 6 3 9 0 7 5 6 7
		   [1795] 2 8 7 2 4 4 2 8 8 5 0 6 8 0 5 7 5 6 1 0 2 2 5 2 7 9 9 1 2 0 7 2 8 9 7 2 7 1 5 3 7 7 0 1 2 3
		   [1841] 8 7 2 9 9 4 6 4 7 1 9 2 0 1 8 8 1 7 2 1 6 8 6 4 5 7 0 1 1 6 9 9 2 7 0 5 0 5 6 5 5 5 6 6 5 9
		   [1887] 8 9 7 4 1 7 2 1 7 5 9 9 3 2 0 1 2 2 3 6 6 8 9 8 5 3 2 3 0 1 1 9 5 3 3 3 0 9 6 6 2 8 2 3 4 7
		   [1933] 6 5 6 6 5 0 3 8 4 2 6 4 4 3 6 7 8 8 0 0 4 2 7 0 2 4 2 3 0 6 4 5 9 4 0 3 6 3 6 5 6 2 8 4 4 4
		   [1979] 1 2 7 2 6 1 1 7 6 8 4 1 7 7 1 4 6 3 1 5 4 2 3 9 1 4 2 5 4 6 9 9 9 9 2 7 2 8 2 7 1 7 5 5 9 5
		   [2025] 5 1 1 2 7 3 7 7 5 2 5 6 9 8 6 0 5 8 8 1 3 9 9 6 7 4 7 6 0 0 1 1 9 4 9 7 9 9 0 0 0 9 6 0 2 7
		   [2071] 2 5 6 5 7 0 5 9 7 3 7 8 2 8 5 8 8 5 0 2 4 3 6 1 0 8 4 9 2 6 9 9 4 4 6 3 8 5 6 7 9 4 7 3 8 4
		   [2117] 5 5 9 3 3 0 6 3 6 4 0 3 4 7 2 5 9 2 8 8 7 3 3 7 0 3 2 1 4 7 7 1 5 4 1 7 8 9 1 7 4 4 7 2 0 7
		   [2163] 2 5 7 3 4 9 2 9 3 3 8 7 2 7 0 5 7 0 5 1 3 4 3 8 0 6 2 0 3 0 5 5 0 3 8 1 8 4 0 2 2 3 7 8 3 7
		   [2209] 8 3 6 5 1 5 4 0 4 7 2 1 8 4 0 2 6 5 9 8 6 8 5 5 1 1 4 0 5 4 2 6 5 3 6 8 4 3 7 6 6 5 2 6 8 1
		   [2255] 1 8 7 0 9 0 1 0 1 6 9 5 1 3 0 4 1 0 5 5 4 5 5 9 3 8 1 2 7 1 2 5 4 0 7 0 6 3 5 5 3 7 1 8 0 6
		   [2301] 6 4 7 7 7 1 5 7 4 0 7 5 1 3 2 0 4 4 6 9 8 0 4 5 8 2 3 0 3 0 2 3 2 4 9 4 5 0 5 2 0 7 7 3 8 3
		   [2347] 1 5 4 0 4 6 0 4 3 9 0 2 8 9 4 7 8 0 9 9 4 2 5 7 6 1 4 2 7 5 0 6 4 3 5 6 1 8 4 8 2 2 1 3 0 9
		   [2393] 2 4 6 8 2 5 5 3 1 6 1 0 2 3 9 6 2 3 5 7 8 5 4 5 0 3 9 4 4 0 6 3 4 3 5 7 4 1 9 1 9 6 3 9 6 9
		   [2439] 8 3 1 1 0 9 3 3 7 0 6 5 9 8 8 0 3 4 7 0 9 2 4 1 8 6 9 2 2 2 9 8 3 3 0 5 9 7 8 0 5 2 4 2 9 4
		   [2485] 8 3 9 2 3 0 4 5 7 5 1 1 3 8 8 4 4 0 1 8 0 0 9 4 4 5 6 3 0 7 4 5 0 3 6 3 4 7 7 9 1 0 5 5 6 4
		   [2531] 1 6 1 8 3 2 9 2 8 2 4 1 9 0 0 2 7 7 3 8 3 6 4 5 0 5 5 4 7 5 3 8 1 4 1 9 4 7 2 6 5 1 6 3 4 9
		   [2577] 7 4 1 1 9 8 8 4 8 7 8 3 8 4 1 2 6 9 3 9 2 0 1 2 2 5 2 6 3 5 8 0 0 8 8 2 1 4 6 4 0 9 4 0 4 7
		   [2623] 1 9 4 6 1 0 1 8 8 3 1 1 4 2 3 1 4 4 4 7 4 8 1 0 3 4 1 4 2 3 9 9 2 2 8 1 1 9 3 8 3 3 3 2 7 5
		   [2669] 1 3 4 2 5 4 5 0 2 5 5 9 7 6 9 2 7 7 4 4 0 2 3 9 1 4 8 4 1 7 4 4 0 3 1 8 6 2 0 4 0 8 4 7 8 9
		   [2715] 6 1 5 8 1 4 4 9 1 0 4 5 4 3 5 2 9 4 7 7 6 6 7 2 5 9 5 8 3 2 7 0 0 4 5 9 8 6 8 2 6 0 1 8 4 5
		   [2761] 7 1 0 1 6 6 7 5 1 7 6 3 4 2 3 6 6 7 3 6 0 8 5 3 6 0 0 8 9 3 7 7 5 4 1 3 1 2 8 4 7 3 8 6 4 6
		   [2807] 7 2 9 4 1 4 0 6 4 3 6 3 9 2 7 0 7 8 6 3 8 8 3 9 6 0 2 0 5 0 7 1 2 6 1 7 5 6 2 9 6 0 2 9 2 7
		   [2853] 4 2 2 4 0 9 2 5 6 5 4 2 7 1 0 0 1 3 8 3 2 9 4 7 9 3 1 6 4 6 2 4 3 1 7 5 9 1 4 0 0 3 5 0 2 6
		   [2899] 8 3 7 4 4 5 0 2 7 4 3 8 3 0 1 8 5 6 2 2 7 0 8 4 7 4 7 8 5 0 9 4 7 5 9 7 7 5 7 9 7 9 9 7 2 1
		   [2945] 2 8 0 2 8 0 8 2 0 4 2 5 6 3 7 1 1 2 9 8 2 6 7 4 6 6 9 5 4 2 7 5 8 8 2 1 3 5 9 9 8 4 7 3 7 7
		   [2991] 8 9 7 6 0 1 9 5 0 6 0 0 3 4 2 0 3 2 2 5 9 6 5 3 2 6 4 5 7 6 7 1 2 2 3 9 4 5 1 7 4 7 0 6 5 1
		   [3037] 1 6 5 4 2 5 9 2 7 4 7 5 1 4 5 6 1 8 2 9 9 4 1 1 6 7 2 6 5 8 7 6 9 6 0 1 9 8 9 7 1 1 2 5 9 3
		   [3083] 4 6 7 0 7 0 9 2 2 8 6 8 9 9 3 2 2 5 9 8 4 6 5 2 7 3 7 2 0 7 7 5 4 6 1 3 6 7 7 4 2 3 5 3 6 9
		   [3129] 1 3 1 1 9 2 1 0 1 9 4 5 9 3 6 2 1 2 4 0 5 1 9 7 7 7 6 4 7 2 4 2 4 5 5 9 6 5 8 5 8 8 4 3 9 5
		   [3175] 8 4 8 7 0 0 2 2 0 3 6 6 4 8 4 0 1 7 2 3 6 9 2 4 6 5 5 8 3 1 5 0 2 7 4 2 5 9 7 6 0 0 8 4 9 3
		   [3221] 3 3 2 8 3 0 6 9 2 9 6 4 3 4 3 6 3 0 4 7 5 2 8 7 6 0 4 2 3 4 5 9 0 6 9 1 2 8 1 0 8 4 3 5 8 9
		   [3267] 5 8 5 2 3 6 2 8 4 1 2 1 2 4 8 1 9 7 0 6 8 6 7 6 7 4 9 7 3 3 2 6 0 6 7 6 3 0 2 7 2 3 8 5 6 8
		   [3313] 4 0 7 7 2 8 0 5 6 9 5 2 2 9 2 9 2 3 0 4 1 5 2 0 1 4 0 3 9 6 7 1 2 3 6 7 6 5 8 5 6 2 2 3 6 6
		   [3359] 6 7 7 2 4 9 6 4 0 8 4 1 7 8 5 7 4 2 6 7 7 2 3 6 2 3 7 6 7 2 7 2 9 3 2 3 0 7 2 1 9 0 3 7 6 0
		   [3405] 8 1 5 2 9 5 3 9 8 5 2 9 2 5 1 6 8 3 2 8 9 7 0 2 2 0 0 8 3 5 7 0 9 9 7 9 1 4 2 2 5 9 0 2 4 6
		   [3451] 1 0 0 9 4 0 7 7 6 5 2 5 1 2 9 5 4 5 8 8 9 7 5 9 2 6 7 7 7 8 5 3 2 3 6 0 1 9 8 0 7 2 1 5 1 1
		   [3497] 4 0 7 7 4 9 5 5 1 4 4 3 3 0 2 7 7 1 4 0 3 5 6 0 8 4 0 7 5 6 5 7 3 0 4 1 5 7 3 2 6 6 1 7 1 2
		   [3543] 2 6 9 0 7 8 2 0 4 1 7 8 3 9 2 7 0 1 8 6 2 8 5 6 9 7 7 4 4 5 0 8 7 7 0 2 3 7 6 4 8 3 2 3 6 2
		   [3589] 9 3 7 8 5 6 4 9 1 3 0 3 4 3 0 2 7 9 0 7 7 3 5 5 3 1 2 3 1 7 7 8 4 0 6 7 4 0 0 5 1 7 6 1 6 6
		   [3635] 7 8 9 9 8 7 3 4 4 4 3 9 2 4 3 1 2 3 3 3 0 1 6 3 4 6 7 3 4 5 8 2 7 6 0 9 6 4 1 7 1 8 9 7 7 1
		   [3681] 5 4 4 8 1 4 1 6 6 0 3 5 7 2 7 5 4 1 2 0 1 9 0 2 6 4 8 9 3 3 0 3 5 9 4 3 0 3 7 7 0 3 3 3 1 2
		   [3727] 2 3 6 7 4 2 7 6 4 1 9 1 6 3 9 0 5 4 5 2 7
		\end{verbatim}
	\end{scriptsize}
	\item SVM, for linear Kernel\\
	
	\begin{scriptsize}
		\begin{verbatim}
		  [1] 7 1 0 6 6 5 6 3 5 3 0 6 6 3 8 4 8 8 1 5 0 6 9 8 9 1 1 2 0 3 4 1 1 0 9 9 6 4 9 6 8 4 0 8 9 8 7 8 0 2 4 0 3 3 3 9 0 3 0 9 4 0 0
		  [64] 6 8 4 5 1 1 4 9 8 3 6 3 6 3 6 4 5 8 7 6 3 1 2 8 0 0 5 7 1 8 3 0 9 2 0 9 1 3 1 3 5 6 6 3 1 6 2 6 8 5 8 3 4 2 4 2 3 4 5 4 2 0 3
		  [127] 1 1 1 6 2 0 3 8 5 5 2 1 2 9 8 0 1 4 6 2 7 4 2 8 9 4 2 6 8 0 6 0 0 8 7 3 7 2 3 9 7 8 6 4 7 2 0 1 8 8 7 4 7 5 7 7 7 1 2 5 1 2 3
		  [190] 5 9 0 6 1 1 6 5 2 2 3 3 7 7 2 0 3 7 4 4 1 2 5 1 0 8 2 8 7 2 2 6 4 7 3 0 9 7 5 8 7 4 9 9 8 1 8 6 9 0 6 2 4 2 0 8 5 2 3 4 7 0 5
		  [253] 9 7 0 0 0 7 7 3 2 0 8 1 3 3 9 9 7 9 3 9 6 2 7 6 6 7 0 9 2 4 3 0 7 2 0 5 2 2 1 9 4 0 9 8 4 5 1 9 6 8 9 3 9 9 9 4 0 7 0 4 1 6 6
		  [316] 6 0 5 8 3 5 9 2 2 3 2 3 9 4 8 9 6 7 1 2 2 8 2 9 1 0 7 2 8 2 4 3 1 7 3 3 9 4 7 7 9 7 3 7 6 2 4 3 0 1 0 1 6 4 1 2 1 8 0 1 4 7 1
		  [379] 7 4 1 3 7 2 1 3 6 1 2 4 3 4 0 0 4 3 8 6 6 1 9 3 3 1 7 6 9 3 5 7 6 8 6 5 4 2 6 0 0 2 9 7 0 9 2 4 5 3 9 2 6 3 9 2 3 6 9 1 4 3 1
		  [442] 4 6 5 0 0 6 8 7 2 7 5 7 8 1 2 3 5 3 2 6 9 0 8 4 0 4 7 0 2 1 0 1 9 7 3 4 4 3 7 1 7 2 2 4 7 3 0 8 6 1 2 0 8 4 9 0 0 9 6 1 6 6 0
		  [505] 7 9 4 0 4 2 7 4 8 8 9 9 2 3 9 2 7 5 4 8 3 3 8 6 2 3 1 5 2 4 0 7 6 5 8 1 6 3 2 6 2 0 7 0 8 2 0 2 9 9 4 2 1 6 2 1 9 8 6 2 6 5 8
		  [568] 5 9 1 2 9 3 5 8 8 8 2 8 2 6 3 6 7 3 4 3 4 0 0 0 1 2 8 8 9 8 4 0 5 1 5 4 8 2 4 2 3 1 2 5 7 1 7 9 0 1 2 2 7 1 9 6 1 2 4 5 6 6 1
		  [631] 7 7 4 3 7 2 1 5 4 3 9 4 1 1 5 5 2 7 3 2 6 7 2 7 6 1 1 9 2 3 8 0 8 0 7 7 5 4 2 2 2 0 0 2 6 7 5 7 0 6 9 7 0 4 2 5 3 3 5 9 2 0 1
		  [694] 3 8 0 8 7 9 9 7 8 9 2 8 2 0 0 0 6 8 9 2 7 2 3 4 9 3 1 6 4 9 0 0 1 6 2 3 3 6 7 3 2 4 1 3 4 1 7 1 0 7 2 8 3 5 5 4 8 7 4 0 0 3 3
		  [757] 3 3 7 6 4 6 1 4 4 2 2 7 9 2 3 3 2 2 1 7 3 4 1 4 7 3 3 5 6 2 2 0 2 5 9 1 7 4 9 7 3 3 9 9 3 2 8 0 4 9 4 5 4 8 7 0 5 1 6 1 6 0 8
		  [820] 4 3 6 7 7 1 0 5 1 0 8 2 4 0 1 1 5 3 7 6 6 0 2 2 8 6 2 2 9 3 6 3 2 8 9 6 8 5 0 7 6 1 9 4 2 3 3 0 4 7 5 1 3 5 0 4 2 2 3 8 2 2 3
		  [883] 5 0 1 2 2 6 2 1 3 5 4 6 7 7 0 3 6 6 5 9 1 7 4 2 6 3 8 5 2 2 2 5 6 6 7 1 2 8 0 6 3 6 5 4 6 1 6 4 1 2 4 5 1 5 4 1 0 9 8 5 9 6 1
		  [946] 3 0 9 1 5 1 6 7 3 2 9 6 8 3 2 0 5 9 0 6 6 3 2 6 9 9 0 3 5 3 2 7 7 3 2 6 5 7 1 1 6 2 8 5 7 5 2 6 7 1 7 6 6 1 1 5 2 7 4 8 3 2 5
		  [1009] 7 0 9 5 5 0 2 2 5 6 7 0 5 2 5 3 8 2 9 5 5 5 9 7 5 9 9 5 1 5 4 3 4 1 3 8 4 8 8 7 3 8 4 4 1 2 4 7 1 4 7 2 8 3 0 4 2 2 9 2 1 3 9
		  [1072] 9 7 5 6 2 0 3 1 7 3 6 8 2 7 6 4 9 2 9 5 1 3 4 1 0 0 3 2 9 9 3 7 3 2 6 2 4 1 5 5 6 3 2 0 2 0 5 1 0 5 0 4 3 5 5 8 0 2 5 1 9 3 2
		  [1135] 2 9 9 6 3 5 4 8 0 8 3 1 2 7 4 4 4 3 2 0 3 9 0 7 5 6 8 1 4 1 3 5 7 8 5 8 7 8 9 1 2 6 9 6 5 1 6 6 7 0 3 2 5 5 3 4 7 2 6 9 6 4 7
		  [1198] 0 4 8 4 4 9 8 9 0 0 2 8 5 9 6 3 8 1 1 6 0 5 9 3 9 4 2 5 7 1 5 4 2 6 8 6 0 1 3 1 2 3 2 4 9 6 4 4 7 9 3 1 7 4 8 5 3 8 0 2 5 0 0
		  [1261] 9 5 2 7 5 0 9 8 0 5 5 2 5 7 0 2 8 7 1 0 2 3 4 5 4 7 8 7 8 4 6 1 0 1 0 3 4 1 4 0 5 3 7 9 6 5 8 7 7 0 6 9 0 8 9 6 7 3 2 6 4 2 3
		  [1324] 1 5 3 0 1 3 3 0 8 9 2 4 7 5 3 6 7 2 2 2 2 1 2 3 4 3 7 8 1 6 6 7 2 3 0 9 6 7 6 7 8 0 2 9 0 4 9 5 6 1 9 4 0 7 5 6 3 9 3 1 6 5 1
		  [1387] 1 5 9 2 5 0 5 6 0 0 3 5 4 4 4 0 5 7 0 8 6 0 0 4 7 0 6 5 2 0 6 2 8 7 0 1 3 5 9 6 4 4 3 5 6 4 4 3 8 8 9 6 6 4 3 6 3 5 5 2 9 7 6
		  [1450] 9 3 0 4 3 4 6 7 9 3 1 5 4 2 6 3 3 8 9 0 4 7 0 5 8 0 5 1 2 1 4 8 2 4 2 6 0 6 8 6 2 3 0 6 3 4 9 4 5 9 9 4 5 7 1 3 6 7 2 8 9 4 6
		  [1513] 2 9 6 9 5 2 1 4 3 0 0 8 3 7 0 4 9 4 0 1 6 8 1 3 6 9 3 0 2 0 4 6 8 2 3 1 6 6 4 4 2 4 0 5 9 4 5 2 6 1 1 3 0 4 2 6 0 3 0 4 8 2 6
		  [1576] 1 1 4 2 0 9 4 0 0 2 5 0 4 2 3 9 9 3 2 0 2 7 9 1 3 7 4 7 1 9 0 3 2 6 6 6 2 4 9 6 2 8 5 5 4 1 8 6 2 0 5 8 0 6 3 4 4 4 6 2 3 0 3
		  [1639] 4 6 0 7 7 2 3 3 9 8 1 5 4 6 3 4 4 2 4 0 3 3 9 4 4 3 8 2 7 1 3 8 4 2 5 2 8 3 8 8 2 8 3 9 4 6 3 6 0 2 0 1 6 6 7 9 2 9 1 6 5 3 6
		  [1702] 2 0 0 1 6 0 7 6 9 4 3 7 2 5 8 8 6 5 7 4 0 6 0 3 6 3 0 9 6 2 6 3 7 3 8 2 0 5 0 2 6 2 9 3 8 4 4 9 5 1 4 3 5 7 1 1 2 4 2 7 1 9 4
		  [1765] 2 1 6 0 4 3 4 0 3 3 0 3 9 2 3 0 5 5 6 2 4 1 6 3 9 0 7 5 6 7 2 8 7 2 4 4 2 8 8 5 0 6 8 0 5 7 5 6 1 0 2 2 5 2 3 9 9 1 2 0 7 2 8
		  [1828] 9 7 2 3 1 5 3 7 7 0 1 2 3 8 7 2 9 9 4 6 4 7 1 9 2 6 1 8 8 1 7 2 1 6 8 6 4 5 7 0 1 1 6 9 9 2 7 0 5 0 5 6 5 5 5 6 6 5 9 8 9 7 4
		  [1891] 1 7 2 1 7 5 9 9 3 2 0 2 2 2 3 6 6 8 9 8 5 3 2 3 0 1 1 1 5 3 3 3 0 9 6 6 2 8 2 3 4 7 6 5 6 6 5 0 3 8 4 2 6 4 4 3 6 7 8 8 0 0 4
		  [1954] 2 7 0 2 4 2 3 0 6 4 5 9 4 0 3 6 3 6 5 6 2 8 4 4 4 1 2 3 2 6 2 1 7 6 8 4 1 7 3 1 4 6 3 1 5 4 2 3 9 1 4 2 5 4 6 9 9 9 9 2 7 2 8
		  [2017] 2 7 1 1 5 5 9 5 5 1 1 2 7 3 7 3 5 2 5 6 9 8 6 0 5 8 8 1 3 9 9 6 7 4 7 6 0 0 1 1 9 4 9 7 9 9 0 0 0 9 6 0 2 7 2 5 6 5 7 0 5 9 3
		  [2080] 3 7 8 2 8 5 8 8 5 0 2 4 3 6 1 0 9 4 9 2 6 9 9 4 4 6 3 3 5 6 7 9 4 7 3 8 4 5 5 9 3 3 0 6 3 6 4 0 3 4 7 2 5 9 2 8 8 7 3 3 3 0 3
		  [2143] 2 1 4 7 7 1 5 4 1 7 8 9 1 7 4 4 7 2 1 7 2 5 7 3 4 9 2 9 3 3 8 7 2 7 0 5 7 0 5 1 3 4 3 8 0 6 2 0 3 0 5 5 0 3 8 1 8 4 0 2 2 3 3
		  [2206] 8 3 7 8 3 6 5 1 5 4 0 4 1 2 1 8 4 0 2 6 5 9 8 6 8 5 5 3 1 4 0 5 4 2 6 5 3 6 8 4 3 7 6 6 5 2 6 8 1 1 8 7 0 9 0 1 0 1 6 9 5 1 3
		  [2269] 0 4 1 0 5 5 4 5 5 9 3 8 1 2 7 1 2 5 4 0 7 0 6 3 5 5 3 1 1 8 0 6 6 4 7 7 7 1 5 7 4 0 7 5 1 3 2 0 4 4 6 9 8 0 4 5 8 2 3 0 3 0 2
		  [2332] 3 2 4 4 4 5 0 5 2 0 7 7 3 8 3 1 5 4 0 4 6 0 4 3 9 0 2 8 9 4 7 8 0 9 9 4 2 5 7 6 1 4 2 7 5 0 6 4 3 5 6 1 8 4 8 2 2 1 3 0 9 2 4
		  [2395] 6 8 2 5 5 3 1 6 1 0 2 3 9 6 2 3 5 3 8 5 4 5 0 3 9 4 4 0 6 3 4 3 5 7 4 1 9 1 9 6 3 9 6 9 8 3 1 1 0 9 3 3 7 0 6 5 9 8 8 0 3 4 7
		  [2458] 0 9 2 4 1 8 6 9 2 2 2 9 8 3 3 0 5 9 7 8 0 5 2 4 2 9 4 8 3 9 2 3 0 4 5 7 5 1 1 3 8 5 4 4 0 1 8 0 0 9 4 4 5 6 3 0 7 4 5 0 3 6 3
		  [2521] 4 7 7 9 1 0 5 5 6 4 1 6 1 8 3 2 9 2 8 2 4 1 9 0 0 2 7 7 3 8 3 6 4 5 0 5 5 4 7 5 3 8 1 4 1 9 4 7 2 6 5 1 6 3 4 9 1 4 1 1 9 8 8
		  [2584] 4 8 7 8 3 8 4 1 2 6 9 3 9 2 0 1 2 2 5 2 6 3 5 8 0 0 8 8 2 2 4 6 4 0 9 4 0 4 7 1 9 4 6 1 0 1 8 8 3 7 1 4 2 3 1 4 4 4 7 4 8 1 0
		  [2647] 3 4 1 4 2 3 9 9 2 2 8 1 1 5 3 8 3 3 3 2 7 5 1 3 4 2 5 4 5 0 2 5 5 9 7 6 9 2 7 7 4 4 0 2 3 9 1 4 8 4 1 7 4 4 0 3 1 8 6 2 0 4 0
		  [2710] 8 4 1 8 9 6 1 5 8 1 4 4 9 1 0 4 5 4 3 5 2 9 4 7 7 6 6 7 2 5 9 5 8 3 2 7 0 0 4 5 9 8 6 8 2 6 0 1 8 4 5 7 1 0 1 6 6 7 5 1 3 6 3
		  [2773] 4 2 3 6 6 1 3 6 0 8 5 3 6 0 0 8 9 3 7 7 5 4 1 3 1 2 8 4 7 3 8 6 4 6 7 2 9 4 1 4 0 6 4 3 6 3 9 2 7 0 7 8 6 3 8 8 3 9 6 0 2 0 5
		  [2836] 0 7 2 2 6 1 7 5 6 2 9 6 0 2 9 2 3 4 2 2 4 0 9 2 5 6 5 4 2 7 1 0 0 1 3 8 3 2 9 4 7 9 3 1 6 4 6 2 4 3 1 7 5 9 1 4 0 0 3 5 0 2 6
		  [2899] 8 3 7 4 4 5 0 2 1 4 3 8 3 0 1 8 5 6 2 2 7 0 8 4 7 4 7 8 5 0 9 4 7 5 9 7 3 1 7 9 7 9 9 7 2 1 2 8 0 2 8 0 8 2 6 4 2 5 6 3 7 1 2
		  [2962] 2 9 8 2 6 7 4 6 6 9 5 4 2 3 5 8 8 2 2 3 5 9 9 8 4 7 3 7 1 8 9 7 6 0 1 9 5 0 6 0 0 3 4 2 0 3 2 2 5 9 6 5 3 2 6 4 5 7 6 7 1 2 2
		  [3025] 3 9 4 5 1 7 4 7 0 6 5 1 1 6 5 4 2 5 9 2 7 4 7 5 1 4 5 6 1 8 2 9 9 4 1 1 6 7 2 6 5 5 7 6 9 6 0 1 9 8 9 3 1 1 2 5 9 3 4 6 7 0 7
		  [3088] 0 9 2 2 8 6 8 9 9 3 2 2 5 9 8 4 6 5 2 7 3 1 2 0 7 7 5 4 6 1 3 6 7 7 4 2 3 5 3 6 9 1 3 1 1 9 2 1 0 1 9 4 5 9 3 6 2 1 2 4 0 5 1
		  [3151] 9 7 7 7 6 4 7 2 4 2 4 5 5 9 6 5 6 5 8 8 4 3 9 5 8 4 8 7 0 0 2 2 0 3 6 6 4 8 4 0 1 7 2 3 6 9 2 4 6 5 5 8 3 1 5 0 2 3 4 2 5 9 7
		  [3214] 6 0 0 8 4 9 3 3 3 2 8 3 0 6 9 2 9 6 4 3 4 3 6 3 0 4 7 5 2 8 7 6 0 4 2 3 4 5 9 0 6 9 1 2 8 1 0 8 4 3 5 8 9 5 8 5 2 3 6 2 8 4 2
		  [3277] 2 1 2 4 8 2 9 7 0 6 8 6 7 6 7 4 9 7 3 3 2 6 0 6 7 6 3 0 2 7 2 3 8 5 6 8 4 0 7 7 2 8 0 5 6 9 5 2 2 9 2 9 2 3 0 4 1 5 2 0 1 4 0
		  [3340] 3 9 6 7 1 2 3 6 1 6 5 8 5 6 2 2 3 6 6 6 7 3 2 4 9 6 4 0 8 4 1 3 8 3 7 4 2 6 7 7 2 3 6 2 3 7 6 7 2 7 2 9 3 2 3 0 7 2 1 9 0 3 7
		  [3403] 6 0 8 1 5 2 9 5 3 9 8 5 2 9 2 5 1 6 8 3 2 8 9 7 0 2 2 0 0 8 3 5 7 0 9 9 7 9 1 4 2 2 5 9 0 2 4 6 1 0 0 9 4 0 3 7 6 5 2 5 1 2 9
		  [3466] 5 4 5 8 8 9 7 5 9 2 6 7 7 7 8 5 3 2 3 6 0 1 9 8 0 7 2 1 5 1 1 4 0 7 7 4 9 5 5 1 4 4 3 3 0 2 7 7 1 4 0 3 5 6 0 8 4 0 3 5 6 5 7
		  [3529] 3 0 4 1 5 7 3 2 6 6 1 7 1 2 2 6 9 0 7 8 2 0 4 1 1 8 3 9 2 7 0 1 8 6 2 8 3 6 9 7 7 4 4 5 0 8 7 1 0 2 3 7 6 4 8 3 2 3 6 2 9 3 7
		  [3592] 8 5 6 4 9 1 3 0 3 4 3 0 2 7 9 0 7 7 3 5 5 3 1 2 3 1 1 7 8 4 0 6 7 4 0 0 5 1 7 6 1 6 6 3 8 9 9 8 7 3 4 4 4 3 9 2 4 3 1 2 3 3 3
		  [3655] 0 1 6 3 4 6 7 3 4 5 8 2 7 6 0 9 6 4 2 7 1 8 9 7 7 1 5 4 4 8 1 4 1 6 6 0 3 5 7 2 7 5 4 1 2 0 2 9 0 2 6 4 8 9 3 3 0 3 5 9 4 3 0
		\end{verbatim}
	\end{scriptsize}
	
	\item SVM, for Gaussian kernel \\
	\begin{scriptsize}
	\begin{verbatim}
	   [1] "7" "1" "0" "6" "6" "5" "6" "3" "5" "1" "0" "6" "6" "3" "8"
  [16] "4" "8" "8" "7" "5" "0" "6" "9" "8" "9" "1" "1" "2" "0" "3"
  [31] "4" "1" "7" "0" "9" "9" "6" "4" "9" "6" "8" "4" "0" "8" "9"
  [46] "8" "7" "8" "0" "2" "4" "0" "3" "3" "3" "9" "0" "3" "0" "9"
  [61] "4" "0" "0" "6" "8" "4" "5" "1" "1" "4" "9" "8" "3" "6" "3"
  [76] "6" "9" "0" "4" "5" "8" "7" "6" "3" "1" "1" "8" "0" "0" "5"
  [91] "7" "1" "8" "3" "0" "9" "2" "0" "9" "1" "9" "1" "3" "5" "6"
 [106] "6" "3" "1" "6" "2" "6" "8" "5" "8" "3" "4" "2" "4" "2" "3"
 [121] "4" "5" "4" "2" "0" "3" "1" "1" "1" "6" "2" "0" "7" "8" "5"
 [136] "5" "2" "1" "2" "9" "8" "0" "1" "4" "6" "2" "7" "4" "2" "8"
 [151] "9" "4" "2" "0" "8" "0" "6" "0" "0" "8" "7" "3" "7" "7" "3"
 [166] "9" "7" "8" "6" "4" "7" "2" "0" "1" "8" "8" "7" "4" "7" "5"
 [181] "7" "7" "7" "1" "2" "5" "1" "2" "3" "5" "9" "0" "6" "1" "1"
 [196] "6" "5" "2" "1" "3" "3" "7" "7" "1" "0" "3" "7" "4" "4" "5"
 [211] "2" "5" "1" "0" "8" "2" "8" "7" "2" "2" "6" "4" "7" "3" "0"
 [226] "9" "7" "9" "8" "7" "4" "9" "9" "8" "1" "8" "6" "9" "0" "6"
 [241] "2" "4" "2" "0" "8" "5" "2" "8" "4" "7" "0" "5" "9" "7" "0"
 [256] "0" "0" "7" "7" "3" "2" "0" "8" "1" "3" "3" "9" "9" "7" "9"
 [271] "3" "9" "6" "2" "7" "6" "6" "7" "0" "9" "2" "4" "3" "0" "7"
 [286] "2" "0" "5" "2" "2" "1" "9" "4" "9" "9" "8" "4" "5" "1" "9"
 [301] "6" "8" "9" "3" "9" "9" "9" "4" "9" "7" "0" "4" "1" "6" "6"
 [316] "6" "0" "5" "8" "3" "5" "9" "2" "2" "3" "2" "3" "9" "4" "8"
 [331] "9" "6" "7" "7" "1" "2" "8" "2" "9" "1" "0" "7" "2" "8" "2"
 [346] "4" "3" "1" "7" "3" "3" "9" "4" "7" "7" "9" "7" "3" "7" "6"
 [361] "2" "4" "3" "0" "1" "0" "9" "6" "4" "1" "2" "7" "8" "0" "1"
 [376] "4" "7" "1" "7" "4" "1" "8" "7" "2" "1" "3" "6" "1" "2" "9"
 [391] "3" "4" "0" "0" "9" "3" "8" "6" "6" "1" "9" "3" "3" "1" "7"
 [406] "6" "9" "1" "5" "7" "6" "8" "6" "5" "4" "2" "6" "0" "0" "2"
 [421] "9" "7" "0" "9" "2" "4" "5" "3" "9" "2" "6" "1" "9" "1" "3"
 [436] "6" "9" "1" "4" "3" "7" "4" "6" "5" "0" "0" "6" "8" "7" "2"
 [451] "7" "5" "7" "8" "7" "2" "1" "5" "3" "1" "6" "9" "0" "8" "4"
 [466] "0" "4" "7" "0" "2" "1" "0" "7" "9" "7" "3" "4" "4" "3" "7"
 [481] "1" "7" "2" "2" "4" "7" "3" "0" "8" "1" "1" "2" "0" "8" "0"
 [496] "9" "0" "0" "9" "6" "1" "6" "6" "0" "7" "9" "4" "0" "4" "1"
 [511] "8" "4" "8" "8" "9" "9" "2" "3" "9" "2" "7" "5" "4" "8" "3"
 [526] "9" "8" "6" "2" "8" "1" "5" "1" "4" "0" "7" "6" "5" "8" "1"
 [541] "6" "3" "2" "6" "1" "0" "7" "0" "8" "2" "0" "1" "9" "9" "4"
 [556] "2" "1" "6" "2" "1" "9" "8" "6" "2" "6" "5" "8" "5" "9" "1"
 [571] "2" "9" "3" "5" "8" "8" "8" "2" "8" "2" "6" "3" "6" "7" "7"
 [586] "4" "3" "4" "0" "9" "0" "1" "2" "8" "8" "9" "8" "4" "0" "5"
 [601] "1" "5" "4" "8" "2" "4" "2" "3" "7" "2" "5" "7" "1" "7" "9"
 [616] "0" "1" "2" "2" "7" "1" "9" "6" "1" "1" "4" "5" "6" "6" "1"
 [631] "7" "1" "4" "3" "7" "1" "1" "5" "4" "3" "9" "4" "1" "1" "5"
 [646] "5" "2" "7" "3" "2" "6" "7" "1" "7" "6" "1" "1" "9" "2" "3"
 [661] "8" "0" "8" "0" "7" "8" "5" "4" "2" "2" "2" "0" "0" "2" "6"
 [676] "7" "5" "7" "0" "6" "9" "7" "0" "4" "2" "5" "3" "3" "5" "9"
 [691] "2" "0" "1" "3" "8" "0" "8" "7" "9" "9" "7" "8" "9" "2" "8"
 [706] "2" "0" "0" "0" "6" "8" "9" "2" "7" "2" "3" "4" "9" "3" "1"
 [721] "6" "4" "9" "0" "0" "1" "6" "2" "3" "3" "6" "7" "3" "2" "4"
 [736] "1" "3" "4" "1" "7" "7" "0" "7" "2" "8" "9" "5" "5" "4" "8"
 [751] "7" "4" "0" "0" "3" "3" "3" "3" "8" "6" "4" "6" "7" "9" "4"
 [766] "2" "2" "7" "9" "1" "3" "3" "2" "1" "1" "7" "8" "4" "1" "4"
 [781] "7" "3" "5" "5" "6" "2" "2" "0" "2" "5" "8" "1" "7" "4" "9"
 [796] "7" "3" "8" "9" "9" "3" "2" "8" "0" "4" "9" "4" "5" "4" "8"
 [811] "7" "0" "5" "1" "6" "1" "6" "0" "8" "4" "3" "1" "7" "7" "1"
 [826] "0" "5" "1" "0" "8" "1" "4" "0" "1" "1" "5" "3" "7" "6" "6"
 [841] "0" "2" "2" "8" "6" "2" "2" "9" "1" "6" "3" "2" "8" "9" "6"
 [856] "8" "5" "0" "7" "6" "1" "9" "4" "2" "3" "3" "0" "4" "7" "5"
 [871] "1" "3" "5" "0" "4" "2" "2" "3" "8" "2" "2" "3" "9" "0" "1"
 [886] "1" "2" "6" "8" "1" "3" "5" "4" "6" "7" "7" "0" "3" "6" "0"
 [901] "5" "9" "1" "7" "4" "2" "6" "9" "8" "5" "1" "2" "2" "5" "6"
 [916] "6" "7" "1" "2" "8" "0" "8" "3" "6" "5" "4" "6" "1" "6" "4"
 [931] "1" "2" "4" "5" "1" "5" "4" "1" "0" "9" "8" "5" "9" "6" "3"
 [946] "3" "0" "9" "7" "5" "1" "6" "7" "7" "2" "9" "6" "8" "3" "2"
 [961] "0" "5" "9" "0" "6" "6" "3" "2" "6" "9" "9" "0" "3" "5" "9"
 [976] "2" "7" "7" "3" "2" "6" "5" "7" "7" "9" "6" "2" "8" "5" "7"
 [991] "5" "2" "6" "7" "1" "7" "6" "6" "1" "1" "5" "2" "8" "4" "8"
[1006] "3" "1" "5" "7" "0" "9" "5" "5" "0" "2" "2" "9" "6" "7" "0"
[1021] "5" "2" "5" "3" "8" "2" "9" "9" "5" "5" "9" "7" "5" "9" "9"
[1036] "5" "1" "5" "4" "8" "4" "1" "3" "8" "4" "8" "8" "7" "3" "8"
[1051] "4" "4" "7" "2" "4" "7" "1" "4" "7" "1" "8" "3" "0" "4" "2"
[1066] "2" "9" "2" "1" "3" "8" "9" "7" "5" "6" "2" "0" "3" "1" "7"
[1081] "8" "6" "8" "2" "7" "6" "4" "9" "2" "9" "9" "7" "1" "4" "1"
[1096] "0" "0" "3" "1" "9" "9" "5" "7" "3" "2" "6" "2" "4" "1" "5"
[1111] "5" "6" "8" "2" "0" "2" "0" "5" "1" "0" "5" "0" "4" "5" "5"
[1126] "5" "8" "0" "2" "5" "1" "9" "3" "2" "1" "9" "9" "6" "3" "5"
[1141] "4" "8" "0" "8" "3" "8" "2" "7" "4" "4" "4" "5" "2" "0" "3"
[1156] "9" "0" "7" "5" "6" "8" "1" "4" "1" "3" "5" "7" "8" "5" "8"
[1171] "7" "8" "9" "1" "2" "6" "9" "6" "5" "7" "6" "6" "7" "0" "3"
[1186] "2" "5" "5" "1" "4" "7" "2" "6" "9" "6" "4" "7" "0" "4" "8"
[1201] "1" "4" "9" "8" "9" "0" "0" "1" "8" "5" "9" "6" "3" "8" "1"
[1216] "1" "6" "0" "5" "9" "1" "9" "4" "2" "5" "7" "1" "5" "4" "1"
[1231] "6" "8" "6" "0" "1" "3" "7" "2" "7" "2" "4" "9" "6" "4" "4"
[1246] "7" "9" "3" "1" "7" "4" "8" "5" "3" "8" "0" "2" "5" "0" "0"
[1261] "9" "5" "2" "7" "5" "0" "9" "8" "0" "5" "5" "2" "5" "7" "0"
[1276] "8" "8" "7" "1" "0" "2" "8" "4" "5" "4" "7" "8" "8" "8" "4"
[1291] "6" "1" "0" "7" "0" "3" "4" "1" "4" "0" "5" "8" "7" "9" "6"
[1306] "5" "8" "7" "7" "0" "6" "9" "0" "8" "9" "6" "7" "3" "2" "6"
[1321] "4" "1" "3" "1" "5" "3" "0" "1" "3" "3" "0" "8" "9" "2" "4"
[1336] "9" "5" "3" "6" "7" "2" "2" "2" "2" "1" "2" "3" "4" "7" "7"
[1351] "8" "1" "6" "6" "7" "2" "7" "0" "9" "6" "7" "6" "7" "8" "0"
[1366] "2" "9" "0" "4" "9" "5" "6" "1" "9" "4" "0" "7" "9" "6" "3"
[1381] "9" "3" "7" "6" "5" "1" "1" "5" "9" "2" "5" "0" "5" "6" "6"
[1396] "0" "3" "8" "4" "4" "4" "0" "5" "7" "0" "8" "6" "0" "0" "4"
[1411] "7" "0" "6" "5" "2" "0" "6" "2" "8" "7" "0" "1" "3" "5" "9"
[1426] "6" "4" "4" "1" "5" "6" "4" "4" "3" "8" "8" "9" "6" "6" "4"
[1441] "3" "6" "7" "5" "5" "2" "9" "7" "6" "9" "3" "0" "4" "3" "4"
[1456] "6" "7" "9" "3" "1" "5" "4" "2" "6" "3" "3" "8" "9" "0" "4"
[1471] "8" "8" "5" "8" "0" "5" "1" "2" "1" "4" "8" "1" "4" "2" "6"
[1486] "0" "6" "8" "0" "2" "3" "0" "6" "8" "4" "9" "4" "5" "9" "9"
[1501] "4" "5" "7" "1" "3" "6" "7" "1" "8" "9" "4" "6" "2" "9" "6"
[1516] "9" "5" "1" "7" "4" "3" "0" "0" "8" "3" "7" "0" "4" "9" "4"
[1531] "0" "1" "6" "8" "1" "8" "6" "9" "3" "0" "2" "0" "4" "6" "8"
[1546] "2" "3" "1" "6" "6" "4" "4" "2" "4" "0" "5" "9" "4" "5" "1"
[1561] "6" "1" "1" "3" "0" "4" "2" "6" "0" "3" "0" "4" "8" "2" "6"
[1576] "7" "7" "4" "2" "0" "9" "4" "0" "9" "2" "5" "0" "4" "2" "1"
[1591] "9" "9" "3" "1" "0" "2" "7" "9" "1" "3" "7" "4" "7" "1" "9"
[1606] "0" "3" "2" "6" "6" "6" "2" "4" "9" "6" "2" "8" "5" "5" "4"
[1621] "7" "8" "6" "2" "0" "5" "8" "0" "6" "3" "4" "4" "0" "6" "1"
[1636] "3" "0" "8" "4" "6" "0" "7" "7" "2" "3" "3" "9" "8" "1" "5"
[1651] "4" "6" "3" "4" "4" "1" "4" "0" "3" "3" "9" "4" "4" "3" "8"
[1666] "2" "7" "3" "3" "8" "4" "2" "5" "2" "8" "3" "8" "8" "2" "8"
[1681] "3" "9" "0" "6" "8" "1" "0" "2" "0" "1" "6" "1" "7" "9" "2"
[1696] "9" "1" "6" "5" "3" "6" "2" "0" "0" "1" "6" "9" "7" "6" "5"
[1711] "4" "3" "7" "2" "5" "8" "8" "6" "5" "7" "4" "0" "6" "0" "3"
[1726] "6" "3" "0" "9" "6" "2" "6" "3" "7" "8" "8" "1" "0" "5" "0"
[1741] "1" "6" "2" "9" "3" "8" "4" "4" "9" "5" "1" "0" "3" "5" "7"
[1756] "1" "1" "2" "4" "2" "7" "9" "9" "4" "2" "1" "6" "0" "4" "3"
[1771] "4" "0" "1" "5" "0" "8" "9" "2" "5" "0" "5" "5" "6" "2" "4"
[1786] "1" "6" "3" "9" "0" "7" "5" "6" "7" "2" "8" "7" "2" "4" "4"
[1801] "2" "8" "8" "5" "0" "6" "8" "0" "5" "7" "5" "6" "1" "0" "2"
[1816] "2" "5" "2" "7" "9" "9" "1" "2" "0" "7" "1" "8" "9" "7" "1"
[1831] "7" "1" "5" "3" "7" "7" "0" "1" "2" "3" "8" "7" "2" "9" "9"
[1846] "4" "6" "4" "7" "1" "9" "2" "0" "1" "8" "8" "1" "7" "2" "1"
[1861] "6" "8" "6" "4" "5" "7" "0" "1" "7" "6" "9" "5" "1" "1" "0"
[1876] "5" "0" "5" "1" "5" "5" "5" "6" "6" "5" "9" "8" "9" "7" "4"
[1891] "1" "7" "2" "1" "7" "5" "9" "9" "3" "2" "0" "1" "2" "2" "3"
[1906] "6" "6" "8" "9" "8" "5" "3" "2" "3" "0" "1" "1" "9" "5" "3"
[1921] "3" "3" "0" "9" "6" "6" "2" "8" "2" "3" "4" "7" "6" "5" "6"
[1936] "6" "5" "0" "3" "8" "4" "2" "6" "4" "0" "3" "6" "7" "8" "8"
[1951] "0" "0" "4" "2" "7" "0" "2" "4" "2" "3" "0" "6" "4" "5" "9"
[1966] "4" "0" "3" "6" "3" "6" "5" "1" "2" "8" "4" "4" "4" "1" "2"
[1981] "7" "2" "6" "1" "1" "7" "6" "8" "4" "1" "7" "7" "1" "4" "6"
[1996] "3" "1" "5" "4" "1" "3" "9" "1" "4" "2" "5" "9" "6" "9" "9"
[2011] "9" "9" "2" "7" "2" "8" "2" "7" "1" "7" "5" "5" "9" "5" "5"
[2026] "7" "1" "2" "7" "5" "7" "7" "5" "1" "5" "6" "9" "8" "6" "0"
[2041] "9" "8" "8" "1" "3" "9" "9" "6" "8" "0" "7" "6" "0" "0" "1"
[2056] "1" "9" "4" "9" "7" "9" "9" "0" "0" "0" "9" "6" "0" "2" "7"
[2071] "2" "5" "6" "5" "7" "0" "5" "9" "8" "1" "7" "8" "2" "8" "5"
[2086] "8" "8" "5" "0" "2" "4" "3" "6" "1" "8" "8" "4" "9" "2" "6"
[2101] "9" "9" "4" "4" "6" "3" "8" "5" "6" "7" "9" "4" "7" "3" "8"
[2116] "4" "5" "5" "9" "3" "1" "0" "6" "3" "6" "4" "0" "3" "4" "7"
[2131] "1" "5" "9" "2" "8" "8" "7" "3" "3" "7" "0" "1" "2" "1" "4"
[2146] "7" "7" "1" "5" "4" "1" "7" "8" "9" "1" "7" "4" "4" "7" "2"
[2161] "9" "7" "1" "5" "7" "3" "4" "9" "2" "9" "3" "3" "8" "7" "2"
[2176] "8" "0" "5" "7" "0" "5" "1" "3" "4" "3" "8" "0" "6" "1" "0"
[2191] "3" "0" "5" "5" "0" "3" "8" "1" "8" "4" "0" "2" "2" "3" "7"
[2206] "8" "3" "7" "8" "3" "6" "5" "1" "5" "4" "0" "4" "7" "2" "1"
[2221] "8" "4" "0" "2" "6" "5" "9" "8" "6" "8" "5" "5" "1" "1" "4"
[2236] "0" "9" "4" "2" "6" "5" "3" "6" "8" "4" "3" "7" "6" "6" "9"
[2251] "2" "6" "8" "1" "1" "8" "7" "0" "9" "0" "7" "0" "1" "6" "9"
[2266] "5" "1" "3" "0" "4" "1" "0" "5" "5" "4" "5" "5" "5" "3" "8"
[2281] "1" "2" "7" "1" "1" "5" "4" "0" "7" "0" "6" "3" "5" "1" "3"
[2296] "7" "1" "8" "0" "6" "6" "4" "7" "7" "7" "1" "5" "7" "4" "0"
[2311] "7" "5" "1" "3" "2" "0" "4" "4" "6" "9" "8" "0" "4" "5" "8"
[2326] "2" "3" "0" "3" "0" "2" "3" "2" "4" "9" "4" "5" "0" "5" "2"
[2341] "0" "8" "7" "3" "8" "3" "5" "5" "4" "0" "4" "6" "0" "4" "3"
[2356] "9" "0" "2" "8" "9" "4" "7" "8" "0" "9" "9" "4" "1" "5" "7"
[2371] "6" "1" "4" "2" "7" "5" "0" "6" "4" "3" "5" "6" "1" "8" "4"
[2386] "8" "2" "2" "1" "5" "0" "9" "2" "4" "6" "8" "1" "5" "5" "3"
[2401] "1" "6" "1" "0" "2" "3" "9" "6" "2" "3" "5" "7" "8" "9" "4"
[2416] "5" "0" "3" "9" "4" "4" "0" "6" "3" "4" "3" "5" "8" "4" "1"
[2431] "9" "1" "9" "6" "3" "9" "6" "9" "8" "3" "1" "1" "0" "9" "3"
[2446] "3" "7" "0" "6" "5" "9" "8" "8" "0" "3" "9" "7" "0" "9" "1"
[2461] "4" "1" "8" "6" "9" "2" "2" "1" "9" "8" "3" "3" "0" "5" "9"
[2476] "7" "8" "0" "5" "2" "4" "2" "9" "4" "8" "3" "9" "2" "3" "0"
[2491] "4" "5" "7" "5" "1" "1" "3" "8" "8" "4" "4" "0" "1" "8" "0"
[2506] "0" "9" "4" "4" "5" "6" "3" "0" "7" "4" "5" "0" "3" "6" "3"
[2521] "4" "7" "7" "9" "1" "0" "5" "8" "6" "4" "1" "6" "7" "8" "3"
[2536] "1" "9" "2" "8" "2" "4" "1" "9" "0" "0" "2" "7" "7" "3" "8"
[2551] "3" "6" "4" "5" "0" "5" "5" "4" "8" "5" "3" "8" "1" "4" "1"
[2566] "9" "8" "7" "2" "6" "5" "1" "6" "3" "4" "9" "7" "0" "1" "3"
[2581] "9" "8" "8" "4" "8" "7" "8" "3" "8" "4" "1" "2" "6" "9" "3"
[2596] "9" "2" "0" "1" "2" "2" "5" "2" "6" "3" "5" "8" "0" "0" "8"
[2611] "8" "2" "1" "4" "1" "4" "0" "9" "4" "0" "4" "7" "1" "9" "4"
[2626] "6" "1" "0" "1" "8" "8" "3" "1" "1" "4" "2" "3" "1" "4" "4"
[2641] "4" "7" "4" "8" "1" "0" "3" "4" "1" "4" "2" "3" "9" "9" "2"
[2656] "2" "8" "1" "1" "9" "3" "8" "3" "3" "3" "2" "7" "5" "1" "3"
[2671] "4" "2" "5" "4" "8" "0" "2" "5" "5" "9" "7" "6" "9" "2" "7"
[2686] "7" "4" "4" "0" "2" "3" "9" "7" "4" "8" "4" "1" "7" "4" "4"
[2701] "0" "3" "1" "8" "6" "2" "0" "4" "0" "8" "4" "7" "8" "9" "6"
[2716] "1" "5" "8" "1" "4" "4" "9" "1" "0" "4" "5" "4" "3" "5" "2"
[2731] "9" "4" "7" "7" "6" "6" "7" "2" "5" "9" "5" "8" "3" "2" "7"
[2746] "0" "9" "4" "5" "9" "8" "6" "8" "2" "6" "0" "1" "8" "4" "5"
[2761] "7" "1" "0" "1" "6" "6" "7" "5" "1" "7" "6" "3" "4" "2" "3"
[2776] "6" "6" "7" "3" "6" "9" "8" "5" "3" "6" "0" "0" "8" "9" "3"
[2791] "7" "7" "5" "4" "1" "3" "1" "2" "8" "4" "7" "3" "8" "6" "4"
[2806] "6" "7" "2" "9" "4" "1" "4" "0" "6" "4" "3" "6" "3" "9" "1"
[2821] "7" "0" "7" "8" "6" "3" "8" "8" "3" "9" "6" "0" "2" "0" "5"
[2836] "0" "7" "1" "8" "6" "1" "7" "5" "6" "2" "9" "6" "0" "2" "9"
[2851] "2" "7" "4" "2" "2" "4" "0" "9" "2" "1" "6" "5" "4" "2" "7"
[2866] "1" "0" "0" "1" "3" "8" "3" "2" "9" "4" "7" "9" "3" "1" "6"
[2881] "4" "6" "2" "4" "3" "1" "7" "5" "9" "1" "4" "0" "0" "3" "5"
[2896] "0" "2" "6" "8" "8" "7" "4" "4" "5" "0" "2" "7" "4" "3" "8"
[2911] "3" "0" "1" "8" "5" "6" "2" "2" "7" "0" "8" "4" "7" "4" "7"
[2926] "8" "5" "0" "9" "9" "7" "5" "9" "7" "7" "1" "7" "9" "7" "5"
[2941] "9" "7" "2" "1" "2" "8" "0" "2" "8" "0" "8" "2" "0" "4" "2"
[2956] "5" "6" "3" "7" "1" "1" "2" "9" "8" "2" "6" "7" "4" "6" "6"
[2971] "9" "5" "4" "2" "7" "5" "8" "8" "2" "1" "3" "5" "9" "9" "8"
[2986] "4" "8" "3" "7" "7" "8" "9" "7" "6" "0" "1" "9" "5" "0" "6"
[3001] "0" "0" "3" "4" "2" "0" "3" "2" "2" "5" "8" "6" "5" "3" "2"
[3016] "6" "4" "5" "7" "6" "8" "1" "2" "1" "3" "9" "4" "5" "1" "7"
[3031] "4" "7" "0" "6" "5" "1" "1" "6" "5" "4" "2" "5" "9" "2" "7"
[3046] "4" "7" "5" "7" "4" "5" "6" "1" "8" "2" "9" "9" "4" "7" "1"
[3061] "6" "7" "2" "6" "5" "8" "7" "6" "9" "6" "0" "4" "9" "8" "9"
[3076] "7" "1" "1" "2" "5" "9" "3" "4" "6" "7" "0" "7" "0" "9" "2"
[3091] "2" "8" "6" "8" "9" "9" "3" "1" "2" "9" "9" "8" "4" "6" "5"
[3106] "2" "7" "3" "7" "2" "0" "7" "7" "5" "4" "6" "1" "3" "6" "7"
[3121] "7" "4" "2" "3" "5" "3" "6" "9" "1" "3" "1" "1" "9" "2" "1"
[3136] "0" "1" "9" "4" "5" "9" "7" "6" "2" "7" "1" "4" "0" "5" "9"
[3151] "9" "8" "7" "7" "6" "4" "7" "2" "4" "2" "4" "5" "5" "9" "6"
[3166] "5" "8" "5" "8" "8" "4" "3" "9" "5" "8" "4" "8" "7" "0" "0"
[3181] "2" "2" "0" "3" "6" "6" "4" "8" "4" "0" "1" "7" "2" "3" "6"
[3196] "9" "2" "4" "6" "5" "5" "8" "3" "1" "5" "0" "2" "8" "4" "2"
[3211] "5" "9" "7" "1" "0" "0" "8" "4" "9" "3" "3" "3" "2" "8" "3"
[3226] "0" "6" "9" "2" "9" "6" "4" "3" "4" "3" "6" "3" "0" "4" "7"
[3241] "5" "2" "8" "7" "6" "0" "4" "2" "3" "4" "5" "9" "0" "6" "9"
[3256] "1" "2" "8" "1" "0" "8" "4" "3" "5" "8" "9" "5" "8" "5" "2"
[3271] "3" "6" "2" "8" "4" "1" "2" "1" "2" "4" "8" "1" "9" "7" "0"
[3286] "6" "8" "6" "7" "6" "7" "0" "9" "7" "3" "3" "2" "6" "0" "6"
[3301] "7" "6" "3" "0" "2" "7" "2" "3" "8" "5" "6" "8" "4" "0" "7"
[3316] "7" "2" "8" "0" "5" "6" "9" "5" "2" "2" "9" "2" "9" "2" "3"
[3331] "0" "4" "1" "5" "2" "0" "1" "4" "0" "3" "9" "6" "7" "1" "2"
[3346] "3" "6" "7" "6" "5" "8" "5" "6" "2" "2" "3" "6" "6" "6" "7"
[3361] "7" "2" "4" "9" "6" "4" "0" "8" "4" "8" "7" "8" "5" "7" "4"
[3376] "2" "6" "7" "7" "2" "3" "6" "2" "3" "7" "6" "7" "2" "8" "2"
[3391] "9" "7" "2" "3" "0" "7" "2" "1" "9" "0" "3" "7" "6" "0" "8"
[3406] "1" "5" "2" "9" "5" "3" "9" "8" "5" "2" "9" "2" "5" "1" "6"
[3421] "8" "3" "2" "8" "9" "7" "0" "1" "2" "0" "0" "8" "3" "5" "7"
[3436] "0" "9" "9" "7" "9" "1" "4" "1" "2" "5" "9" "0" "2" "4" "6"
[3451] "1" "0" "0" "9" "4" "0" "7" "7" "6" "5" "2" "5" "1" "2" "9"
[3466] "5" "4" "5" "8" "8" "9" "7" "5" "9" "1" "6" "7" "7" "7" "8"
[3481] "5" "3" "2" "3" "6" "0" "1" "9" "8" "0" "7" "2" "1" "5" "1"
[3496] "1" "4" "0" "7" "7" "4" "9" "5" "5" "1" "4" "4" "3" "3" "9"
[3511] "2" "7" "7" "1" "4" "0" "3" "5" "6" "0" "8" "4" "0" "8" "5"
[3526] "6" "5" "7" "3" "0" "4" "1" "5" "7" "3" "2" "6" "6" "7" "7"
[3541] "1" "2" "2" "6" "9" "0" "7" "8" "1" "0" "4" "1" "7" "8" "3"
[3556] "9" "2" "7" "0" "1" "8" "6" "2" "8" "5" "6" "9" "7" "7" "4"
[3571] "4" "5" "0" "8" "7" "7" "0" "2" "3" "7" "6" "4" "8" "3" "1"
[3586] "3" "6" "2" "9" "3" "7" "8" "5" "6" "4" "9" "1" "3" "0" "3"
[3601] "4" "3" "0" "2" "7" "9" "0" "7" "7" "3" "5" "5" "3" "7" "2"
[3616] "3" "1" "7" "7" "8" "4" "0" "6" "7" "4" "0" "0" "5" "1" "7"
[3631] "1" "1" "6" "6" "8" "8" "9" "9" "8" "7" "3" "4" "4" "4" "3"
[3646] "9" "2" "4" "3" "1" "2" "3" "3" "1" "0" "1" "6" "3" "4" "6"
[3661] "7" "3" "4" "5" "8" "2" "7" "6" "0" "9" "6" "0" "1" "7" "1"
[3676] "8" "9" "8" "7" "1" "5" "4" "4" "8" "1" "4" "1" "6" "6" "0"
[3691] "3" "5" "7" "2" "7" "5" "4" "1" "2" "0" "1" "9" "0" "2" "6"
[3706] "4" "8" "9" "3" "3" "0" "3" "5" "9" "4" "3" "0" "3" "7" "7"
[3721] "0" "3" "3" "3" "1" "1" "1" "3" "6" "8" "4" "2" "7" "6" "4"
[3736] "1" "9" "2" "6" "3" "9" "0" "5" "4" "5" "1" "7"
	\end{verbatim}
	\end{scriptsize}
	
\end{itemize}
 
 
\section{Problem 6}
Note that by doing transfer learning, we need to add $Y(W_s^TX+W_{os})$ (which is constant) to our constraint. That is, $y_i(W_s^Tx_i+W_{os})+y_i(W_t^Tx_i+W_{ot}) \geq 1$. \\
Objective function: \[\arg \min_{w_t,w_{ot}} \dfrac{1}{2} ||w||\]
s.t. $y_i(W_s^Tx_i+W_{os})+y_i(W_t^Tx_i+W_{ot}) \geq 1$\\

To simply the equation, Let $ C_i=y_i(W_s^Tx_i+W_{os})$. Then the constraint becomes:
\[y_i(W_s^Tx_i+W_{os})\geq 1 -C_i\]

To get the optimized estimators, we use Lanrange Multiplier. That is: 
\begin{equation}
L_p= \dfrac{1}{2}||w||^2- \sum_{i=1}^N \alpha'[y_i(w^Tx_i+w_o)-(1-C_i)]
\end{equation}


Take derivate with respect to $w$ and $w_0$, we will get 
\[ \dfrac{\partial L_p}{\partial w}: w-\sum \alpha_iy_ix_i=0 \rightarrow w=\sum \alpha_iy_ix_i\]

\[ \dfrac{\partial L_p}{\partial w_o}:  0=\sum \alpha_iy_i\]

Substitute the partial derivative into (1), we will get the objective function to be: 
\begin{equation}
\arg \min \dfrac{1}{2}\sum_i\sum_j \alpha_i \alpha_j y_iy_jx_ix_j+\sum_i (1-C_i) \alpha_i
\end{equation}

Then we use the Quadratic Programming function (QP) to get the estimated $\alpha$. then obtain the resulting $w_t$ and $w_{ot}$.
\[w_t=\sum \alpha_iy_ix_i\]
\[w_{ot}=-\dfrac{1}{2}(wx^+ +wx^-)\]
The above derivation is important for training the target data and use the fit function to predict the testing data. The added constraints will cause the QP function changed. 
\\

\textbf{Our Algorithm:} 
\begin{itemize}
	\item Step 0: To have a better result, we all use Gaussian Kernel with $\sigma^2=\sqrt{8}$\\
	
	\item Step 1: Train the Source data and obtain a constant \[ C_i=y_i(W_s^T\phi(x_i)+W_{os})=
	y_i(\sum_j \alpha_j^{(s)} y_j^{(s)}\phi(x_j^{(s)} )\phi(x_i)+w_{o}^{(s)})\]. Where $\alpha_j^{(s)}$ and $w_{o}^{(s)}$ are obtained from the QP optimization.\\
	
	\item Step 2: Train the Target data by adding $C_i$ in the constraint part, in Equation (2).
	\begin{equation*}
	\arg \min \dfrac{1}{2}\sum_i\sum_j \alpha_i \alpha_j y_iy_jx_ix_j+\sum_i (1-C_i) \alpha_i
	\end{equation*} The resulting Langrange Multiplier objective function has been derived above. Get the resulting $w_t, w_{ot}$ \\
	
	\item Step 3: Apply the estimated $w_t, w_{ot}$ to the fit function $f=sign(w_t x+w_{ot})$.  Use it along with the Testing data to get the predictions. 
\end{itemize}

\textbf{Result:}
Again, the prediction results are also available in .csv file. 
\begin{verbatim}
  [1] "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8"
 [16] "8" "8" "8" "8" "0" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8"
 [31] "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8"
 [46] "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8"
 [61] "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8"
 [76] "8" "8" "8" "8" "8" "8" "8" "8" "0" "0" "8" "8" "8" "8" "8"
 [91] "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "8" "0" "0" "0" "0"
[106] "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0"
[121] "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0"
[136] "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0"
[151] "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0"
[166] "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "0" "8" "8"
[181] "8" "8" "8" "0" "0" "0" "8" "8" "8" "8" "0" "0" "0" "0" "0"
[196] "0" "0" "0" "0" "0" "0" "0"

\end{verbatim}

\section{Code}
\subsection{K-nn code (Using R Program)}
\begin{verbatim}
Knn=function(k,train,test,cl){
if (k>1){
distance=sapply(1:nrow(train),function(i) dist(rbind(test,train[i,])))
ind=order(distance)[1:k]

classBelong=cl[ind]
result.class=unique(classBelong)
find_max=sapply(1:length(result.class),
function(i) length(which(classBelong==result.class[i])))
index= which(find_max==max(find_max))
result=result.class[index]
}

if (k==1){
distance=sapply(1:nrow(train),function(i) dist(rbind(test,train[i,])))
ind=order(distance)[1]

classBelong=cl[ind]
result=classBelong
}
return (result)
} #KNN function
Knn=cmpfun(Knn)
#################
#next do the 3-fold cross validation 
Knn.CV=function(train,cl,k,n.cv){
N=nrow(train)
n=floor(N/n.cv)

x=sample(N)
g=as.factor(c(rep(1:n.cv,rep(n,n.cv)),rep(n.cv,(N-n*n.cv))))
S=split(x,g)
for (i in 1:n.cv){
training=train[-S[[i]],]
testing=train[S[[i]],]
cl.cv=cl[-S[[i]]]
true.value=cl[S[[i]]]
result=c()
err=numeric(n.cv)
count=0
  check=c()
  yy=c()

for (l in 1:nrow(testing)){
result[l]= Knn(k,training,testing[l,],cl.cv)
if (result[l]!=true.value[l])
count=count+1

} #end of for loop for each testing individual

 ##############
 
 err[i]=count/nrow(testing)
 check=cbind(result,check)
 yy=cbind(true.value,yy)
 #cat("yy\n",yy,"\n","check\n",check,"\n")
 }
 
 total_error= sum(err)
 confusion=table(check,yy)
 
 return(list(err=total_error/3*100, confusion=confusion))
}

#####################
result_comparison11= Knn.CV(pendigits.train[,1:16],y,k=1,n.cv=3)
result_comparison55= Knn.CV(pendigits.train[,1:16],y,k=5,n.cv=3)
result_comparison5050= Knn.CV(pendigits.train[,1:16],y,k=50,n.cv=3)


pen_predict1=sapply(1:nrow(pendigits.test.nolabels),
function(i) Knn(k=1,pendigits.train[,1:16],pendigits.test.nolabels[i,],y))

pen_predict5=sapply(1:nrow(pendigits.test.nolabels),
function(i) Knn(k=5,pendigits.train[,1:16],pendigits.test.nolabels[i,],y))

pen_predict50=sapply(1:nrow(pendigits.test.nolabels),
function(i) Knn(k=50,pendigits.train[,1:16],pendigits.test.nolabels[i,],y))



\end{verbatim}

\subsection{SVM Code (Using Python Program)}
\begin{verbatim}
import numpy as np
from numpy import linalg
import cvxopt
import cvxopt.solvers
from sklearn.cross_validation import KFold
from sklearn.metrics import confusion_matrix
np.set_printoptions(threshold = np.nan)


def linear_kernel(x1, x2):
    return np.dot(x1, x2)

def polynomial_kernel(x, y, p=2):
    return (1 + np.dot(x, y)) ** p

def gaussian_kernel(x, y, sigma=5.0):
    return np.exp(-linalg.norm(x-y)**2 / (2 * (sigma ** 2)))

class SVM(object):

    def __init__(self, kernel=linear_kernel, C=None):
        self.kernel = kernel
        self.C = C
        if self.C is not None: self.C = float(self.C)

    def fit(self, X, y):
        n_samples, n_features = X.shape

        # Gram matrix
        K = np.zeros((n_samples, n_samples))
        for i in range(n_samples):
            for j in range(n_samples):
                K[i,j] = self.kernel(X[i], X[j])

        P = cvxopt.matrix(np.outer(y,y) * K)
        q = cvxopt.matrix(np.ones(n_samples) * -1) # plus the C from previous test
        A = cvxopt.matrix(y, (1,n_samples))
        b = cvxopt.matrix(0.0)

        if self.C is None:
            G = cvxopt.matrix(np.diag(np.ones(n_samples) * -1))
            h = cvxopt.matrix(np.zeros(n_samples))
        else:
            tmp1 = np.diag(np.ones(n_samples) * -1)
            tmp2 = np.identity(n_samples)
            G = cvxopt.matrix(np.vstack((tmp1, tmp2)))
            tmp1 = np.zeros(n_samples)
            tmp2 = np.ones(n_samples) * self.C
            h = cvxopt.matrix(np.hstack((tmp1, tmp2)))

        # solve QP problem
        solution = cvxopt.solvers.qp(P, q, G, h, A, b)

        # Lagrange multipliers
        a = np.ravel(solution['x'])

        # Support vectors have non zero lagrange multipliers
        sv = a > 1e-5
        ind = np.arange(len(a))[sv]
        self.a = a[sv]
        self.sv = X[sv]
        self.sv_y = y[sv]
        print "%d support vectors out of %d points" % (len(self.a), n_samples)

        # Intercept
        self.b = 0
        for n in range(len(self.a)):
            self.b += self.sv_y[n]
            self.b -= np.sum(self.a * self.sv_y * K[ind[n],sv])
        if len(self.a) != 0: self.b /= len(self.a)

        # Weight vector
        if self.kernel == linear_kernel:
            self.w = np.zeros(n_features)
            for n in range(len(self.a)):
                self.w += self.a[n] * self.sv_y[n] * self.sv[n]
        else:
            self.w = None
         def project(self, X):
        if self.w is not None:
            return np.dot(X, self.w) + self.b
        else:
            y_predict = np.zeros(len(X))
            for i in range(len(X)):
                s = 0
                for a, sv_y, sv in zip(self.a, self.sv_y, self.sv):
                    s += a * sv_y * self.kernel(X[i], sv)
                y_predict[i] = s
            return y_predict + self.b

    def predict(self, X):
        return (self.project(X))
\end{verbatim}

\end{document}